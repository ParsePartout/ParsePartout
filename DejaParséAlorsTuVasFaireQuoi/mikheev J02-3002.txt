Nom du fichier :
			mikheev J02-3002.pdf
Titre :
			Periods, Capitalized Words, etc.
Nombre d'auteur :
 			1
Auteur :
			Andrei Mikheev
Abstract :
			In this article we present an approach for tackling three important aspects of text normalization: sentence boundary disambiguation, disambiguation of capitalized words in positions where capitalization is expected, and identification of abbreviations. As opposed to the two dominant techniques of computing statistics or writing specialized grammars, our document-centered approach works by considering suggestive local contexts and repetitions of individual words within a document. This approach proved to be robust to domain shifts and new lexica and produced performance on the level with the highest reported results. When incorporated into a part-of-speech tagger, it helped reduce the error rate significantly on capitalized words and sentence boundaries. We also investigated the portability to other languages and obtained encouraging results.

References :			
			Aberdeen, John S., John D. Burger, David S.
			Day, Lynette Hirschman, Patricia
			Robinson, and Marc Vilain. 1995. "Mitre:
			Description of the alembic system used for MUC-6." In Proceedings of the Sixth
			Message Understanding Conference (MUC-6),
			Columbia, Maryland, November. Morgan
			Kaufmann.
			Baldwin, Breck, Christine Doran, Jeffrey
			Reynar, Michael Niv, Bangalore Srinivas, and Mark Wasson. 1997. "EAGLE: An extensible architecture for general linguistic engineering." In Proceedings of
			Computer-Assisted Information Searching on
			Internet (RIAO '97), Montreal, June.
			Baum, Leonard E. and Ted Petrie. 1966.
			Statistical inference for probabilistic functions of finite Markov chains. Annals of Mathematical Statistics 37:1559-1563.
			Bikel, Daniel, Scott Miller, Richard
			Schwartz, and Ralph Weischedel. 1997.
			"Nymble: A high performance learning name-finder." In Proceedings of the Fifth
			Conference on Applied Natural Language
			Processing (ANLP'97), pages 194-200.
			Washington, D.C., Morgan Kaufmann.
			Brill, Eric. 1995a. Transformation-based error-driven learning and natural language parsing: A case study in part-of-speech tagging. Computational
			Linguistics 21(4):543-565.
			Brill, Eric. 1995b. "Unsupervised learning of disambiguation rules for part of speech tagging." In David Yarovsky and Kenneth
			Church, editors, Proceedings of the Third
			Workshop on Very Large Corpora, pages
			1-13, Somerset, New Jersey. Association for Computational Linguistics.
			Burnage, Gavin. 1990. CELEX: A Guide for
			Users. Centre for Lexical Information,
			Nijmegen, Netherlands.
			Mikheev Periods, Capitalized Words, etc.
			Chinchor, Nancy. 1998. "Overview of
			MUC-7." In Seventh Message Understanding
			Conference (MUC-7): Proceedings of a
			Conference Held in Fairfax, April. Morgan
			Kaufmann.
			Church, Kenneth. 1988. "A stochastic parts program and noun-phrase parser for unrestricted text." In Proceedings of the
			Second ACL Conference on Applied Natural
			Language Processing (ANLP'88), pages
			136-143, Austin, Texas.
			Church, Kenneth. 1995. "One term or two?"
			In SIGIR'95, Proceedings of the 18th Annual
			International ACM SIGIR Conference on
			Research and Development in Information
			Retrieval, pages 310-318, Seattle,
			Washington, July. ACM Press.
			Clarkson, Philip and Anthony J. Robinson.
			1997. "Language model adaptation using mixtures and an exponentially decaying cache." In Proceedings IEEE International
			Conference on Speech and Signal Processing,
			Munich, Germany.
			Cucerzan, Silviu and David Yarowsky. 1999.
			"Language independent named entity recognition combining morphological and contextual evidence." In Proceedings of
			Joint SIGDAT Conference on EMNLP and
			VLC.
			Francis, W. Nelson and Henry Kucera. 1982.
			Frequency Analysis of English Usage: Lexicon and Grammar. Houghton Mifflin, New
			York.
			Gale, William, Kenneth Church, and David
			Yarowsky. 1992. "One sense per discourse." In Proceedings of the Fourth
			DARPA Speech and Natural Language
			Workshop, pages 233-237.
			Grefenstette, Gregory and Pasi Tapanainen.
			1994. "What is a word, what is a sentence? Problems of tokenization." In
			The Proceedings of Third Conference on
			Computational Lexicography and Text
			Research (COMPLEX'94), Budapest,
			Hungary.
			Krupka, George R. and Kevin Hausman.
			1998. Isoquest Inc.: Description of the netowl extractor system as used for
			MUC-7. In Proceedings of the Seventh
			Message Understanding Conference (MUC-7),
			Fairfax, VA. Morgan Kaufmann.
			Kuhn, Roland and Renato de Mori. 1998. A cache-based natural language model for speech recognition. IEEE Transactions on
			Pattern Analysis and Machine Intelligence
			12:570-583.
			Kupiec, Julian. 1992. Robust part-of-speech tagging using a hidden Markov model.
			Computer Speech and Language.
			Mani, Inderjeet and T. Richard MacMillan.
			1995. "Identifying unknown proper names in newswire text." In B. Boguraev and J. Pustejovsky, editors, Corpus
			Processing for Lexical Acquisition. MIT Press,
			Cambridge, Massachusetts, pages 41-59.
			Marcus, Mitchell, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: The
			Penn treebank. Computational Linguistics
			19(2):313-329.
			Mikheev, Andrei. 1997. Automatic rule induction for unknown word guessing.
			Computational Linguistics 23(3):405-423.
			Mikheev, Andrei. 1999. A knowledge-free method for capitalized word disambiguation. In Proceedings of the 37th
			Conference of the Association for
			Computational Linguistics (ACL'99), pages
			159-168, University of Maryland, College
			Park.
			Mikheev, Andrei. 2000. "Tagging sentence boundaries." In Proceedings of the First
			Meeting of the North American Chapter of the
			Computational Linguistics (NAACL'2000), pages 264-271, Seattle, Washington.
			Morgan Kaufmann.
			Mikheev, Andrei, Clair Grover, and Colin
			Matheson. 1998. TTT: Text Tokenisation Tool.
			Language Technology Group, University of Edinburgh. Available at http://www.ltg.ed.ac.uk/software/ttt/ index.html.
			Mikheev, Andrei, Clair Grover, and Marc
			Moens. 1998. Description of the ltg system used for MUC-7. In Seventh
			Message Understanding Conference
			(MUC-7): Proceedings of a Conference Held in
			Fairfax, Virginia. Morgan Kaufmann.
			Mikheev, Andrei and Liubov Liubushkina.
			1995. Russian morphology: An engineering approach. Natural Language
			Engineering 1(3):235-260.
			Palmer, David D. and Marti A. Hearst. 1994.
			"Adaptive sentence boundary disambiguation." In Proceedings of the
			Fourth ACL Conference on Applied Natural
			Language Processing (ANLP'94), pages
			78-83, Stuttgart, Germany, October.
			Morgan Kaufmann.
			Palmer, David D. and Marti A. Hearst. 1997.
			Adaptive multilingual sentence boundary disambiguation. Computational Linguistics
			23(2):241-269.
			Park, Youngja and Roy J. Byrd. 2001.
			"Hybrid text mining for finding abbreviations and their definitions." In
			Proceedings of the Conference on Empirical
			Methods in Natural Language Processing
			(EMLP'01), pages 16-19, Washington,
			D.C. Morgan Kaufmann.
			Ratnaparkhi, Adwait. 1996. "A maximum entropy model for part-of-speech
			Computational Linguistics Volume 28, Number 3 tagging." In Proceedings of Conference on
			Empirical Methods in Natural Language
			Processing, pages 133-142, University of
			Pennsylvania, Philadelphia.
			Reynar, Jeffrey C. and Adwait Ratnaparkhi.
			1997. "A maximum entropy approach to identifying sentence boundaries." In
			Proceedings of the Fifth ACL Conference on
			Applied Natural Language Processing
			(ANLP'97), pages 16-19. Morgan
			Kaufmann.
			Riley, Michael D. 1989. "Some applications of tree-based modeling to speech and language indexing." In Proceedings of the
			DARPA Speech and Natural Language
			Workshop, pages 339-352. Morgan
			Kaufmann.
			Yarowsky, David. 1993. "One sense per collocation." In Proceedings of ARPA
			Human Language Technology Workshop '93, pages 266-271, Princeton, New Jersey.
			Yarowsky, David. 1995. "Unsupervised word sense disambiguation rivaling supervised methods." In Meeting of the
			Association for Computational Linguistics
			(ACL'95), pages 189-196.

Conclusion :


Discussion :
			In this article we presented an approach that tackles three important aspects of text nor-
			malization: sentence boundary disambiguation, disambiguation of capitalized words
			when they are used in positions where capitalization is expected, and identification of
			abbreviations. The major distinctive features of our approach can be summarized as
			follows:
			* We tackle the sentence boundary task only after we have fully
			disambiguated the word on the left and the word on the right of a
			potential sentence boundary punctuation sign.
			* To disambiguate capitalized words and abbreviations, we use
			information distributed across the entire document rather than their
			immediate local context.
			* Our approach does not require manual rule construction or data
			annotation for training. Instead, it relies on four word lists that can be
			generated completely automatically from a raw (unlabeled) corpus.
			In this approach we do not try to resolve each ambiguous word occurrence individu-
			ally. Instead, the system scans the entire document for the contexts in which the words
			in question are used unambiguously, and this gives it grounds, acting by analogy, for
			resolving ambiguous contexts.
			We deliberately shaped our approach so that it largely does not rely on precom-
			piled statistics, because the most interesting events are inherently infrequent and hence
			are difficult to collect reliable statistics for. At the same time precompiled statistics
			would be smoothed across multiple documents rather than targeted to a specific docu-
			ment. By collecting suggestive instances of usage for target words from each particular
			document on the fly, rather than relying on preacquired resources smoothed across the
			entire document collection, our approach is robust to domain shifts and new lexica
			and closely targeted to each document.
			314
			Computational Linguistics Volume 28, Number 3
			A significant advantage of this approach is that it can be targeted to new domains
			completely automatically, without human intervention. The four word lists that our
			system uses for its operation can be generated automatically from a raw corpus and
			require no human annotation. Although some SBD systems can be trained on relatively
			small sets of labeled examples, their performance in such cases is somewhat lower than
			their optimal performance. For instance, Palmer and Hearst (1997) report that the SATZ
			system (decision tree variant) was trained on a set of about 800 labeled periods, which
			corresponds to a corpus of about 16,000 words. This is a relatively small training set
			that can be manually marked in a few hours' time. But the error rate (1.5%) of the
			decision tree classifier trained on this small sample was about 50% higher than that
			when trained on 6,000 labeled examples (1.0%).
			The performance of our system does not depend on the availability of labeled
			training examples. For its "training," it uses a raw (unannotated in any way) corpus
			of texts. Although it needs such a corpus to be relatively large (a few hundred thousand
			words), this is normally not a problem, since when the system is targeted to a new
			domain, such a corpus is usually already available at no extra cost. Therefore there is no
			trade-off between the amount of human labor and the performance of the system. This
			not only makes retargeting of such system easier but also enables it to be operational
			in a completely autonomous way: it needs only to be pointed to texts from a new
			domain, and then it can retarget itself automatically.
			Although the DCA requires two passes through a document, the simplicity of the
			underlying algorithms makes it reasonably fast. It processes about 3,000 words per
			second using a Pentium II 400 MHz processor. This includes identification of abbre-
			viations, disambiguation of capitalized words, and then disambiguation of sentence
			boundaries. This is comparable to the speed of other preprocessing systems.3 The oper-
			ational speed is about 10% higher than the training speed because, apart from applying
			the system to the training corpus, training also involves collecting, thresholding, and
			sorting of the word lists--all done automatically but at extra time cost. Training on
			the 300,000-word NYT text collection took about two minutes.
			Despite its simplicity, the performance of our approach was on the level with
			the previously highest reported results on the same test collections. The error rate
			on sentence boundaries in the Brown corpus was not significantly worse than the
			lowest quoted before (Riley 1989: 0.28% vs. 0.20% error rate). On the WSJ corpus
			our system performed slightly better than the combination of the Alembic and SATZ
			systems described in Palmer and Hearst (1997) (0.44% vs. 0.5% error rate). Although
			these error rates seem to be very small, they are quite significant. Unlike general POS
			tagging, in which it is unfair to expect an error rate of less than 2% because even human
			annotators have a disagreement rate of about 3%, sentence boundaries are much less
			ambiguous (with a disagreement of about 1 in 5,000). This shows that an error rate
			of 1 in 200 (0.5%) is still far from reaching the disagreement level. On the other hand,
			one error in 200 periods means that there is one error in every two documents in the
			Brown corpus and one error in every four documents in the WSJ corpus.
			With all its strong points, there are a number of restrictions to the proposed ap-
			proach. First, in its present form it is suitable only for processing of reasonably "well-
			behaved" texts that consistently use capitalization (mixed case) and do not contain
			much noisy data. Thus, for instance, we do not expect our system to perform well
			on single-cased texts (e.g., texts written in all capital or all lower-cased letters) or on
			3 Palmer and Hearst (1997) report a speed of over 10,000 sentences a minute, which with their average
			sentence length of 20 words equals over 3,000 words per second, but on a slower machine (DEC Alpha
			3000).
			315
			Mikheev Periods, Capitalized Words, etc.
			optical character reader-generated texts. We noted in Section 8 that very short doc-
			uments of one to three sentences also present a difficulty for our approach. This is
			where robust syntactic systems like SATZ (Palmer and Hearst 1997) or the POS tagger
			reported in Mikheev (2000), which do not heavily rely on word capitalization and are
			not sensitive to document length, have an advantage.
			Our DCA uses information derived from the entire document and thus can be
			used as a complement to approaches based on the local context. When we incorpo-
			rated the DCA system into a POS tagger (Section 8), we measured a 30-35% cut in the
			error rate on proper-name identification in comparison to DCA or the POS-tagging
			approaches alone. This in turn enabled better tagging of sentence boundaries: a 0.20%
			error rate on the Brown corpus and a 0.31% error rate on the WSJ corpus, which corre-
			sponds to about a 20% cut in the error rate in comparison to DCA or the POS-tagging
			approaches alone.
			We also investigated the portability of our approach to other languages and ob-
			tained encouraging results on a corpus of news in Russian. This strongly suggests that
			the DCA method can be applied to the majority of European languages, since they
			share the same principles of capitalization and word abbreviation. Obvious exceptions,
			though, are German and some Scandinavian languages in which capitalization is used
			for things other than proper-name and sentence start signaling. This does not mean,
			however, that the DCA in general is not suitable for preprocessing of German texts--it
			just needs to be applied with different disambiguation clues.
			Initially the system described in this article was developed as a text normalization
			module for a named-entity recognition system (Mikheev, Grover, and Moens 1998) that
			participated in MUC-7. There the ability to identify proper names with high accuracy
			proved to be instrumental in enabling the entire system to achieve a very high level of
			performance. Since then this text normalization module has been used in several other
			systems, and its ability to be adapted easily to new domains enabled rapid develop-
			ment of text analysis capabilities in medical, legal, and law enforcement domains.

