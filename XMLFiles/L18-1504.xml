<article>
	<preamble>L18-1504.pdf</preamble>
	<titre>A New Annotated Portuguese/Spanish Corpus for the Multi-Sentence Compression Task</titre>
	<auteurs>
		<auteur>
			<name>Elvys Linhares Pontes</name>
			<mail>elvys.linhares-pontes@univ-avignon.fr</mail>
            <affiliation>CERI/LIA, Universite d'Avignon et des Pays de Vaucluse, Avignon, France 2Ecole Polytechnique de Montreal, Montreal, Canada 3Universidade Federal do Ceara, Sobral-CE, Brasil</affiliation>
      </auteur>
		<auteur>
			<name>Juan-Manuel Torres-Moreno</name>
			<mail>juan-manuel.torres@univ-avignon.fr</mail>
            <affiliation>CERI/LIA, Universite d'Avignon et des Pays de Vaucluse, Avignon, France 2Ecole Polytechnique de Montreal, Montreal, Canada 3Universidade Federal do Ceara, Sobral-CE, Brasil</affiliation>
      </auteur>
		<auteur>
			<name>Stephane Huet</name>
			<mail>stephane.huet@univ-avignon.fr</mail>
            <affiliation>CERI/LIA, Universite d'Avignon et des Pays de Vaucluse, Avignon, France 2Ecole Polytechnique de Montreal, Montreal, Canada 3Universidade Federal do Ceara, Sobral-CE, Brasil</affiliation>
      </auteur>
		<auteur>
			<name>Andrea Carneiro Linhares</name>
			<mail>andrea.linhares@ufc.br</mail>
            <affiliation>CERI/LIA, Universite d'Avignon et des Pays de Vaucluse, Avignon, France 2Ecole Polytechnique de Montreal, Montreal, Canada 3Universidade Federal do Ceara, Sobral-CE, Brasil</affiliation>
      </auteur>
	</auteurs>
	<abstract>Abstract Multi-sentence compression aims to generate a short and informative compression from several source sentences that deal with the same topic. In this work, we present a new corpus for the Multi-Sentence Compression (MSC) task in Portuguese and Spanish. We also provide on this corpus a comparison of two state-of-the-art MSC systems.</abstract>
	<introduction>Among the various applications of Natural Language Pro-cessing, Automatic Text Summarization (ATS) aims atsummarizing one or more texts automatically. Summariza-tion systems identify relevant data and create a summaryfrom key information. The (Multi-)Sentence Compressiontask can be seen as a subproblem of ATS with the objectiveto generate a shorter, informative and correct sentence fromsource sentence(s).In many cases, state-of-the-art NLP systems are evaluatedwith experiments restrained to the English language, in partbecause there are a lot of available English resources formost NLP tasks. As regards Multi-Sentence Compression(MSC), the available resources are unfortunately limited; toour knowledge, only one dataset is freely available and it isconfined to the French language (Boudin and Morin, 2013).In this work, we present a new annotated corpus in the Por-tuguese and Spanish languages for the MSC task. Usingthis corpus, we evaluate two state-of-the-art systems andshow that the use of several languages leads to more miti-gated results on the superiority of one system than the useof the French corpus alone.The remainder of this paper is organized as follows. In Sec-tion 2, we characterize MSC with respect to related tasksfrom the perspective of the available corpora. Section 3describes the creation and the features of our corpus. InSection 4 we analyze the results achieved by state-of-the-art methods using our dataset. Finally, conclusions are setout in Section 5.</introduction>
	<body>2. Related WorkSentence Compression (SC) aims at producing a reducedgrammatically correct sentence from a source sentence. SCcan be used in the context of the abstractive summarizationof documents, the generation of article titles or the simpli-fication of complex sentences, using diverse methods (opti-mization, syntactic structure, deletion of words and/or gen-eration of sentences). The corpora for SC can be dividedin two categories: deletion-based and summarization-basedSC.In the case of SC by deletion of words, sentences arecompressed by removing irrelevant words (Filippova et al.,2015; Ive and Yvon, 2016). Knight and Marcu (2002) de-veloped a SC corpus by aligning abstracts and sentencesextracted from the Ziff-Davis corpus, which is a collec-tion of newspaper articles announcing computer products.Clarke and Lapata (2008) provided two manually createdtwo-reference corpora for deletion-based compression. Fil-ippova and Altun (2013), and Filippova et al. (2015) ex-tracted and released deletion-based compressions by align-ing news headlines to the first sentences. Finally, Ive andYvon (2016) developed an English-French parallel corpusfor the compression and simplification tasks.SC by generations of sentences analyzes a whole sentenceand generates a new shorter sentence with the core infor-mation of the source sentence (Rush et al., 2015; Gan-itkevitch et al., 2011; Cohn and Lapata, 2008; Toutanovaet al., 2016). Ganitkevitch et al. (2011) created a corpusof compression paraphrases composed of parallel English-English sentences obtained from multiple reference transla-tions. Rush et al. (2015) produced compression pairs madeup of the headline of each article and its first sentence; theyreleased their code to extract data from the annotated Gi-gaword (Graff et al., 2011). Cohn and Lapata (2008) andToutanova et al. (2016) describe two manually created ab-stractive compression corpora that are publicly available.The dataset presented in Cohn and Lapata (2008) comprisesa single-reference sentence pairs for abstractive summary,while the corpus developed by Toutanova et al. (2016) hasmultiple references for short paragraph compressions.Multi-Sentence Compression (MSC), also known as Multi-Sentence Fusion, is a variation of SC. MSC aims at ana-lyzing a cluster of similar sentences to generate a new sen-tence, which is shorter than the average length of sourcesentences and has the key information of the cluster (Barzi-lay and McKeown, 2005; Filippova, 2010). MSC enablessummarization and question-answering systems to gener-3192CharacteristicsFrench Portuguese SpanishSource Reference Source Reference Source Reference#tokens 20,224 2,362 17,998 1,425 30,588 3,694#vocabulary (tokens) 2,867 636 2,438 533 4,390 881#sentences 618 120 544 80 800 160avg. sentence length (tokens) 33.0 19.7 33.1 17.8 38.2 23.1type-token ratio 38.8% 50.1% 33.7% 67.9% 35.2% 43.4%sentence similarity [0,1] 0.46 0.67 0.51 0.59 0.47 0.64Table 1: Statistics of the corpora.ate outputs combining fully formed sentences from one orseveral documents. Various corpora have been developedfor MSC and are composed of clusters of similar sentencesfrom different source news in English, French, Spanish orVietnamese languages (Barzilay and McKeown, 2005; Fil-ippova, 2010; Boudin and Morin, 2013; Thadani and McK-eown, 2013; Luong et al., 2015). Filippova's corpus aswell as Boudin and Morin's contain clusters of similar sen-tences, each cluster composed of at least 7 or 8 sentences,whereas the datasets introduced in (McKeown et al., 2010)and (Luong et al., 2015) have only a pair of source sen-tences per cluster. McKeown et al. (2010) collected 300English sentence pairs taken from newswire clusters usingAmazon's Mechanical Turk. Likewise, the dataset built byLuong et al. (2015) contains 250 Vietnamese sentences di-vided into 115 groups of similar sentences with 2 sentencesper group. Thadani and McKeown (2013) presented an En-glish corpus with 1,858 clusters having between 2 and 4sentences; this dataset was built using automatic methodsfrom annotations made for the DUC1 and TAC2 evalua-tions. The corpora presented in (McKeown et al., 2010),(Boudin and Morin, 2013) and (Luong et al., 2015) are pub-licly available, but among these three datasets only the sec-ond one is more suited to multi-document summarizationor question-answering tasks because the documents to ana-lyze are usually composed of many similar sentences.3. Dataset DescriptionWe introduce a novel annotated corpus collected from Por-tuguese and Spanish Google News.3 This corpus is com-posed of clusters of similar sentences along with referencecompressions for each cluster. The data are described in thefollowing subsections. Table 1 summarizes the characteris-tics of the corpus and Table 2 shows a small example of ourPortuguese dataset.3.1. Source SentencesIn keeping with the methodology introduced by Filippova(2010), we collected links from Google News in Spanishand Portuguese between July and September 2016. Theselinks redirect international news sites in Spanish (La Jor-nada, Milenio, El Economista, BBC Mundo, El Colom-biano, El Pais, CNN en espanol, etc.) and in Portuguese1http://duc.nist.gov2http://www.nist.gov/tac3The Spanish and Portuguese MSC datasets are freely avail-able, under GPL license on the DOI website: http://dev.termwatch.es/fresa/CORPUS/MSF2/.(G1, Uol Noticias, Estadao, O Globo, etc.). Each cluster iscomposed of related sentences describing a specific eventand was chosen among the first sentence from different ar-ticles about Science, Sports, Economy, Health, Business,Technology, Accidents/Catastrophes, General Informationand other subjects. During the collection period, sentenceswere gathered among news threads that had at least 8 dif-ferent sources. The source sentences of each cluster weremanually selected so that they best describe the news, whilesentences dealing with less relevant information were dis-carded. Each source sentence is composed of at least 8 to-kens and a verb. In order to ensure the variability of sourcesentences inside a cluster, we removed all duplicated sen-tences, by assuming that sentences were too similar whenthe cosine similarity4 computed from one-hot vectors washigher that 0.8. We used the TreeTagger system5 to tag thesource sentences with Parts-of-Speech.3.2. Reference CompressionsLike in (Filippova, 2010; Boudin and Morin, 2013), ref-erence compressions are edited by human annotators, allnative Portuguese or Spanish speakers, who analyzed themost relevant facts of a cluster and generated a condensedsentence of this cluster. We suggested that the annotatorsshould use the same vocabulary and n-grams as the sourcesentences and only select the most relevant informationabout the topic. We also recommended that they shouldgenerate compressions that are shorter than the length aver-age of the source sentences. The following sections providedetails about the Portuguese and Spanish parts of the cor-pus and, as a matter of comparison, briefly recalls the maincharacteristics of the French corpus built by Boudin andMorin.3.2.1. Portuguese DatasetThe Portuguese corpus is composed of 40 clusters. Eachcluster has at least 10 similar sentences by topic and 2 refer-ence compressions made by 2 human annotators. This cor-pus contains 17,998 tokens and has a vocabulary of 2,438tokens. Source sentences have an average of 33.1 tokensper sentence with a standard deviation of 9.9 tokens. TheType-Token Ratio (TTR) indicates the reuse of tokens inthe cluster and is defined by the number of unique tokensdivided by the number of tokens in each cluster; the lower4The cosine similarity between two vectors u and v associatedwith two sentences is defined by u*v||u|| ||v||in the [0,1] range.5Website: http://www.cis.uni-muenchen.de/schmid/tools/TreeTagger/3193Source sentences :A Tesla fez uma oferta de compra a empresa de servicos de energia solar SolarCity por mais de 2300 milhoes de euros.A Tesla Motors , fabricante de carros eletricos , anunciou aquisicao da SolarCity por US$ 2,6 bilhoes .A fabricante de carros eletricos e baterias Tesla Motors disse nesta segunda-feira ( 1 ) que chegou a um acordo com aSolarCity para comprar a instaladora de paineis solares por US$ 2,6 bilhoes , em um grande passo do bilionario ElonMusk para oferecer aos consumidores um negocio totalmente especializado em energia limpa , informou a Reuters .Reference compressions :A Tesla Motors anunciou acordo para comprar a SolarCity por US$ 2,6 bilhoes .A fabricante Tesla Motors vai adquirir a instaladora de paineis solares da SolarCity .Table 2: Small example of our Portuguese dataset.the TTR, the greater the reuse of tokens in the cluster. Thesentence similarity represents the average cosine similarityof the sentences in a cluster. Using these metrics, referenceshave an average length of 17.8 tokens and a standard devi-ation of 1.5 tokens, while the Portuguese source corpus hasa TTR of 33.7%. The Portuguese annotators generated thecompressions with a TTR of 67.9% and a sentence similar-ity of 0.59. Finally, the average compression ratio betweenthe reference and source sentences is 54%.3.2.2. Spanish DatasetThe Spanish part is also composed of 40 clusters. It has30,588 tokens and a vocabulary of 4,390 tokens. Each clus-ter has 20 similar sentences on the same topic and 4 refer-ence compressions made by 4 human annotators. Sourcesentences have an average of 38.2 tokens per sentence witha standard deviation of 10.7 tokens and an average TTR of35.2%. Reference compressions contain the same vocab-ulary as source sentences while keeping an average size of23.1 tokens, a standard deviation of 2.4 tokens and a TTR of43.4%. The sentence similarity between the compressionsis 0.64. The average compression rate is 61%.3.2.3. French DatasetWe used in the following experiments the French corpusdeveloped by Boudin and Morin (2013). This corpus alsohas 40 clusters composed of 618 sentences (33 tokens onaverage). The clusters are composed of 15 sentences onaverage and the TTR of the corpus is 38.8%. Referencecompressions have a compression rate of 60%.4. Experimental EvaluationWe used our corpus to provide a more thorough evalua-tion of state-of-the-art approaches for MSC than the studyon the French corpus alone. We tested on our dataset asimple baseline, as well as (Filippova, 2010) and (Boudinand Morin, 2013) methods. Filippova modeled clusters ofsimilar sentences as Word Graphs based on the cohesionof tokens and their Part-of-Speech (PoS). Inspired by thegood results of the Filippova's method, Boudin and Morinused the TextRank method as a re-rank method to analyzethe sentences generated by Filippova's method in order toproduce well punctuated and hopefully more informativecompressions. The baseline system creates a Word Graph(WG) like Filippova's method, but this time all arcs havethe same weight. Then, the system generates a compres-sion represented by the shortest path in the WG that hasat least 8 tokens. Algorithms were implemented using thePython programming language and the takahe6 library.4.1. Automatic and Manual MetricsThe most important features of MSC are informativenessand grammaticality. Informativeness is the percentage ofthe main information retained in the compression, whilegrammaticality analyzes whether a sentence is correct ornot.References are assumed to contain the most importantinformation. Thus we calculated informativeness scoresbased on the common information between the output ofthe MSC system and the references using ROUGE (Lin,2004). In particular, we used the f-measure metricsROUGE-1, ROUGE-2 and ROUGE-SU4. Like in Boudinand Morin (Boudin and Morin, 2013), ROUGE metrics arecalculated using stop words removal and stemming.7We also led a manual evaluation with 4 native speakersfor each language. The native speakers of each languagejudged the compression in two aspects: informativenessand grammaticality. In the same way as (Filippova, 2010;Boudin and Morin, 2013), the native speakers evaluated thegrammaticality in a 3-point scale: 0 point for an ungram-matical compression, 1 point for compression with minormistakes; and 2 points for a correct compression. The in-formativeness evaluation process is similar for grammati-cality: 0 point if the compression is not related to the maintopic, 1 point if the compression misses some relevant in-formation and 2 points if the compression conveys the gistof the main event.4.2. Results with Automatic MetricsTable 3 shows f-score ROUGE scores for the French, Por-tuguese and Spanish datasets.8 Boudin and Morin's systemgenerated better compressions with higher ROUGE scoresthan Filippova's and the baseline for all datasets.6Website: http://www.florianboudin.org/publications.html7http://snowball.tartarus.org/8Although we used the same system and data as (Boudin andMorin, 2013) for the French corpus, we were not able to repro-duce exactly their results. The ROUGE scores given in their arti-cle are close to ours for their system: 0.6568 (ROUGE-1), 0.4414(ROUGE-2) and 0.4344 (ROUGE-SU4), but using Filippova'ssystem we measured higher scores than them: 0.5744 (ROUGE-1), 0.3921 (ROUGE-2) and 0.3700 (ROUGE-SU4).3194MethodFrench Portuguese SpanishRG-1 RG-2 RG-SU4 RG-1 RG-2 RG-SU4 RG-1 RG-2 RG-SU4Baseline 0.3681 0.1904 0.1758 0.3199 0.1273 0.1309 0.2700 0.0990 0.0984Filippova (2010) 0.6384 0.4423 0.4297 0.5388 0.2971 0.2938 0.5004 0.2983 0.2847Boudin and Morin (2013) 0.6674 0.4672 0.4602 0.5532 0.3029 0.2868 0.5140 0.2960 0.2801Table 3: ROUGE f-scores measured on the French, Portuguese and Spanish datasets. The best ROUGE results are in bold.Table 4 provides statistics on the length and the compres-sion ratio of the sentences generated by the systems. Thebaseline system output the shortest compressions, whichtranslated into the worst ROUGE scores. For the threetested datasets, Filippova's method generated shorter com-pressions with a smaller standard deviation than Boudinand Morin's system. Let us note that for this last systemthe lengths of the outputs are less regular across the threelanguages.The Portuguese and Spanish languages derive from Latinand are closely related languages. However, they differ inmany details of their grammar and lexicon. Moreover, thedatasets produced for the three languages are unlike accord-ing to several features. First, our corpus contains a smaller(Portuguese corpus) and a larger (Spanish corpus) datasetin terms of sentences than the original French corpus. Be-sides, the compression rates of the three datasets (see Sec-tion 3.) indicates that the Portuguese source sentences havemore irrelevant tokens. The sentence similarity (Table 1,last line) describes the variability of sentences in the sourcesentences and in the references, and reflects here that thesentences are slightly more diverse for the Portuguese cor-pus. It can be noticed that the references are more similartoo each other than source sentences since they only retainthe main information. Finally, the French corpus has a TTRof 38.8% whereas the Portuguese and Spanish datasets haveTTRs of 33.7% and 35.2%, respectively.The baseline system generated the shortest compression be-cause all arcs of the WG have the same weights. However,this system analyzes neither the grammaticality nor themost used n-grams in the clusters. Consequently, the base-line system generated compressions with the worst ROUGEscores.4.3. Human EvaluationROUGE only analyzes the overlapping between the candi-date compression and the references. Since this analysis isnot reliable enough, we led a further manual evaluation tostudy the informativeness and grammaticality of compres-sions, as described in Section 4.1.. Given the poor resultsof the baseline with ROUGE, we only analyzed the Filip-pova's and Boudin and Morin's methods (Table 5).We measured inter-rater agreement on the judgments wecollected, obtaining values of Fleiss' kappa of 0.418, of0.305 and 0.364 for French, Portuguese and Spanish re-spectively. These results show that human evaluation israther subjective. Questioning evaluators on how they pro-ceed to rate sentences reveals that they often made theirchoice by comparing outputs for a given cluster. As thedifferences of the grammaticality and the informativenessscores for the methods are not statistically significant, wemove our investigation on the average and standard de-viation of the results. Both methods generated compres-sions of good quality (scores higher than 1) for all datasets,especially for the French and the Portuguese parts wherescores above 1.5 for grammaticality and above 1.2 for in-formativeness were obtained. Filippova's method gener-ated more correct compressions (except for the Portuguesecorpus where both methods obtained almost the same re-sults), which shows that the re-ranking step tends to mod-erately deteriorate grammaticality. By contrast, Boudinand Morin's method consistently improves informative-ness, which validates the interest of integrating the anal-ysis of key phrases inside candidate compressions. This re-ranking method combines the cohesion score of Filippovaand the relevance of key phrases9 to generate more infor-mative compression. This method selects the path of WordGraph that has relevant key phrases even if this path has alower cohesion quality.All in all, Boudin and Morin's method generated more in-formative but also longer compressions than Filippova's,CR showing a relative increase of 18% between both sys-tems (Table 4).</body>
	<conclusion>Multi-Sentence Compression aims to generate a short infor-mative text summary from several sentences with relatedand redundant information. This task can be used in thedomain of multi-document summarization or question an-swering to provide more informative and concise texts.In this paper, we presented a new annotated corpus intwo languages that extends the French data made availablein (Boudin and Morin, 2013). We also compared two state-of-the art systems on this new dataset. We hope this cor-pus will help the NLP community to develop and validatemulti-language methods for multi-sentence compression.In order to extend the multi-language resources to more di-verse languages, we plan to create a similar MSC datasetfor Arabic. We also want to use our corpus to test othercompetitive MSC systems, such as the one based on integerlinear programming we introduced in (Linhares Pontes etal., 2016).</conclusion>
	<discussion>N/A</discussion>
	<biblio>Barzilay, R. and McKeown, K. R. (2005). Sentence fusionfor multidocument news summarization. ComputationalLinguistics, 31(3):297-328, September.Boudin, F. and Morin, E. (2013). Keyphrase extractionfor N-best reranking in multi-sentence compression. InNAACL, pages 298-305.Clarke, J. and Lapata, M. (2008). Global inference forsentence compression: An integer linear programmingapproach. Journal of Artificial Intelligence Research(JAIR, 31:399-429.Cohn, T. and Lapata, M. (2008). Sentence compressionbeyond word deletion. In COLING, pages 137-144.Filippova, K. and Altun, Y. (2013). Overcoming the lack ofparallel data in sentence compression. In EMNLP, pages1481-1491.Filippova, K., Alfonseca, E., Colmenares, C. A., Kaiser,L., and Vinyals, O. (2015). Sentence compression bydeletion with LSTMs. In EMNLP, pages 360-368.Filippova, K. (2010). Multi-sentence compression: Find-ing shortest paths in word graphs. In COLING, pages322-330.Ganitkevitch, J., Callison-Burch, C., Napoles, C., andDurme, B. V. (2011). Learning sentential paraphrasesfrom bilingual parallel corpora for text-to-text genera-tion. In EMNLP, pages 1168-1179.Ive, J. and Yvon, F. (2016). Parallel sentence compression.In COLING, Technical Papers, page 1503-1513.Knight, K. and Marcu, D. (2002). Summarization beyondsentence extraction: A probabilistic approach to sentencecompression. Artificial Intelligence, 139(1):91-107.Lin, C.-Y. (2004). ROUGE: A Package for AutomaticEvaluation of Summaries. In Workshop Text Summariza-tion Branches Out (ACL'04), pages 74-81.Linhares Pontes, E., Gouveia da Silva, T., Linhares,A. C., Torres-Moreno, J.-M., and Huet, S. (2016).Metodos de otimizacao combinatoria aplicados ao prob-lema de compressao multifrases. In Anais do XLVIIISimposio Brasileiro de Pesquisa Operacional (SBPO),pages 2278-2289.Luong, A. V., Tran, N. T., Ung, V. G., and Nghiem, M. Q.(2015). Word graph-based multi-sentence compression:Re-ranking candidates using frequent words. In Sev-enth International Conference on Knowledge and Sys-tems Engineering (KSE), pages 55-60.McKeown, K., Rosenthal, S., Thadani, K., and Moore, C.(2010). Time-efficient creation of an accurate sentencefusion corpus. In HLT-NAACL, pages 317-320.Rush, A. M., Chopra, S., and Weston, J. (2015). A neuralattention model for abstractive sentence summarization.In EMNLP, pages 379-389.Thadani, K. and McKeown, K. (2013). Supervised sen-tence fusion with single-stage inference. In Sixth Inter-national Joint Conference on Natural Language Process-ing, IJCNLP, pages 1410-1418.Toutanova, K., Brockett, C., Tran, K. M., and Amershi,S. (2016). A dataset and evaluation metrics for abstrac-tive compression of sentences and short paragraphs. InEMNLP, pages 340-350.8. Language Resource ReferencesBoudin, Florian and Morin, Emmanuel. (2013).Keyphrase Extraction for N-best Reranking in Multi-Sentence Compression. NAACL (2013). Available onhttps://github.com/boudinfl/lina-msc.Graff, David and Cieri, Christopher and Kong, Junbo andChen, Ke and Maeda, Kazuaki. (2011). English Gi-gaword. Linguistic Data Consortium, 5th, ISLRN 911-942-430-413-0.3196</biblio>
</article>