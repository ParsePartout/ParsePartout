<article>
	<preamble>HapticSymposium2024_Lacote-lq.pdf</preamble>
	<titre>Comparing the Haptic Perception of Directional Information Using a Uni-manual or Bi-manual Strategy</titre>
	<auteurs>
		<auteur>
			<name>Ines Lacote</name>
			<mail>1Univ Rennes@irisa.fr)</mail>
            <affiliation>N/A</affiliation>
      </auteur>
		<auteur>
			<name>International License</name>
			<mail> INSA Rennes@irisa.fr)</mail>
            <affiliation>N/A</affiliation>
      </auteur>
		<auteur>
			<name>Claudio Pacchierotti</name>
			<mail> CNRS@irisa.fr)</mail>
            <affiliation>N/A</affiliation>
      </auteur>
	</auteurs>
	<abstract>Abstract-- This paper evaluates the haptic perception of directional cues conveyed through one or two handles mounted on a walker, with the objective of devising haptic rendering techniques for aiding people with diverse mobility, sensory, and cognitive impairments. We designed a haptic handle composed of a cylindrical soft plastic casing, which houses five custom voice-coil actuators distributed around the handle. We carried out a human subject study enrolling 14 participants to investigate the impact of using uni-manual or bi-manual conditions and to identify the most effective tactile patterns in a navigation assistance scenario. We tested the use of either vibration bursts or pressure "taps" to convey different directions of motion, relying on the concept of the apparent haptic motion illusion. Results show that the proposed technique is an effective approach for providing navigational cues. We identified specific patterns that were highly effective both in uni or bi-manual conditions in conveying directional instructions towards the front (93.7%), the back (90.5%), the left (97.2%), and the right (84.5%) directions, highlighting the viability of both strategies and their adaptability to various single or dualhandle mobility devices. No significant difference was found between providing vibratory or tapping signals.</abstract>
	<introduction>When focusing on mobility issues for people with visualimpairments, a major point of interest is navigation assis-tance. Because autonomy is an important element to assuremental health for people with sensory impairments [1], [2],researchers have tried to develop new tools to assist peoplein their displacements. As the sense of vision is altered, usershave to rely on the other ones to understand the world andnavigate safely [3], [4]. To compensate the sensory losses,researchers have developed audio apparatus, such as theSonicGuide [5] or the Laser Cane [6], and haptic devices,like the Smart Cane [7], the Buru-Navi3 [8] the Animotusdevice [9], and the S-Ban [10]. Users with moderate to severevisual impairments (MSVI) who also need mobility aids,such as a walker or a power wheelchair [11] have needsthat sometimes do not fit the solutions adapted for MSVIThis work was supported by Inria Defi Project "DORNELL". This workinvolved human subjects or animals in its research. Approval of all ethicaland experimental procedures and protocols was granted by Inria's ethicscommittee (COERLE) under Application No. 2021-39.1Univ Rennes, INSA Rennes, CNRS, Inria, IRISA, 35708 Rennes, France(e-mail: {name.surname}@irisa.fr).2CNRS, Univ Rennes, Inria, IRISA, 35708 Rennes, France (e-mail:claudio.pacchierotti@irisa.fr).3Univ Rennes, INSA Rennes, LGCGM, 35708 Rennes, France4CNRS, Sorbonne Universite, ISIR, 75005 Paris, France (e-mail: gue-orguiev@isir.upmc.fr).5Institut Universitaire de France (IUF).users with no mobility deficiencies. In this respect, audioindications have the advantage of being easy to broadcast andunderstand. However, there are also drawbacks associatedwith using audio technologies for guidance, especially forpeople with visual impairments. Indeed, it has been shownthat people use their hearing to safely move in outdoorenvironments [12] and they may want their assistive devicesto be quiet and private. Consequently, there is a growinginterest for providing navigation information trough othermeans, including haptics [13]. Haptic navigation cues canbe provided via vibrations [7], [11], shape changing ob-jects [10], [14], or skin stretch [15]-[17]. In the spectrumof vibratory haptics for navigation assistance, Wachaja etal. [18] investigated obstacle avoidance and navigation strate-gies when using a walker adapted for the elderly. Theyused multiple vibrotactile actuators distributed on the handlesof a walker and in a belt, and concluded that participantsrather prefer the information on the walker handles thanaround the waist. However, providing information throughmultiple vibrotactile signals can also lead to cognitive fatigueand difficulty in discerning them [19]. Another exploratorysubject for navigation assistance is the use of haptic illusionas a mean to convey rich information with limited hardware.The apparent haptic motion (AHM) is one of the maintools that can be used to provide continuous directionalindications [18], [20], [21], as it conveys the impressionof continuous movement by activating discrete stimulationpoints [22]. It consists of the discrete mechanical or electro-tactile stimuli presented sequentially on the skin conveyinga sensation of movement [22], [23]. For this reason, in ourprevious works [24], [25], we investigated the ability of "tap"stimulations, which are short pressure stimuli, to convey theapparent haptic motion illusion and, in turn, directional cues.Results showed that the proposed "tap" stimulation was asefficient as a 120 Hz vibrotactile stimulation in generatinghaptic motion illusion. They showed encouraging resultsfor eliciting directional cues when the user's hand rests ona curved surface, suggesting a potential use on hand-helddevices [25]. Actuators could however be improved for aclearer omni-directional use of tap stimulations.This paper presents the results of an experimental eval-uation aiming at comparing different haptic rendering tech-niques on a walker as a navigation assistance device. Specif-ically, we compared the effectiveness of providing eithervibrations or "taps" to convey navigation information throughthe AHM paradigm, either through a single handle or twohandles mounted on a walker.</introduction>
	<body>II. EXPERIMENTAL DEVICEa. b.ActuatorAttachmentfor the walkerFig. 1. Right and left haptic handles for giving directional tactile sensations.a) CAD of the soft 3D printed handle made out of TPU, 5 alcoves areincluded to house the actuators along and around the handle in a "T"-shape, so as to stimulate the thumb, the second metacarpal bone of thepalm, and the index finger. b) Picture of the two handles, symmetricallydesigned to fit the two hands. For technical details, also see [25].We designed a haptic handle composed of five electro-magnetic actuators, shown in Fig. 1. Its design is inspiredfrom one of our earlier works [25], but features an improvedactuator design (see Fig. 2) and positioning, as well asthe miniaturisation of the conditioning system for easierintegration onto the walker. The handle is 3D printed out ofTPU soft material (Filaflex 82A, 0.8 mm thickness). Its shaperesembles that of a cylinder, and it has been designed to becomfortably held in one hand. The actuators are distributedacross the handle in a "T"-configuration, so as to stimulatethe metacarpal bones of the palm (three motors), thumb(one motor), and index (one motor) fingers. The handle isdesigned to be attached on a standard walker (ErgoClick 4wheels walker), replacing the default handles of this assistivedevice. Fig. 3.b shows how a user holds the handle and howit is attached to the walker.The actuators are custom electromagnetic motors inspiredby the Hapticomm device [26] and used in previous studieson the AHM illusion [24], [25], [27]. They can conveyboth vibratory and tap signals, detailed in [25]. They arecomposed of coils as stators and magnets fixed in theirrepulsive position as movers, see Fig. 2.a. The contactbetween the actuators and the user's skin is made through acustom membrane, 3D printed out of TPU soft material, anddesigned to be threaded onto the coil with a cross shape onthe top, keeping its top sufficiently soft and elastic, witha central space to glue the magnets (see Fig 2.b). Thismembrane acts as a lid and it is inserted onto the actuator.The actuators are then inserted in the handle dedicatedalcoves from the inside with their attached membrane. Withthis design, the mover's rest position is up in the coil, gluedon the membrane, no matter the orientation of the motor.When not electrically powered, the magnets stay maintainedby the membrane in a neutral position. Its activation resultsin the extension of the membrane inside or outside the coildepending on the voltage sent to the actuator.With respect to our previous handle [24], [25], [27], thesetup was miniaturised, going from a 25L suitcase needingsector plugging to a 2L box. The original amplifiers andthe National Instrument controller were replaced by M5stacks and powered with a 12V, 3A power supply, thatcould be replaced by a power bank for portability (capacity:10Ah/37Wh, Output: 6-9V DC, max 2A). This portabilityeffort is crucial for future implementations in actual displace-ment on walkers and other mobility aids.Magnets/moverstator3D printedsupportCoil/10Soft 3D printedmembranea. b. c.167Fig. 2. Our custom-design electromagnetic actuator with the soft 3D-printed membrane. Five of these actuators are housed inside each handle(see Fig. 1). a) Cut view. b) Isometric View. c) Picture of the actuator.III. USER STUDYWe carried out a study to understand whether (i) differentstimulation modes (vibrations, "taps"), (ii) rendering patterns(twelve patterns, distributed around or along the handles),and (iii) number of active handles (one, two) affect theperformance of navigation assistance on a walker deliveredthrough the AHM paradigm. This study has been approvedby Inria's ethics committee (COERLE, n 2021-39).A. Experimental setup and methods1) SetupThe setup is composed of a standard walker, equipped withtwo haptic handles (Fig. 3b.), which are placed at 48 cm fromeach other, while their height can be adjusted for the comfortof the user. The walker has its brakes on and the participantsstand behind it, hands placed on the haptic handles, as aneveryday user would do. Participants wear noise-cancellingheadphones and are facing a table, illustrating the possibledirectional interpretation they can give. The walker and theuser do not move throughout the experiment.2) Characterisation of tactile patternsWe employ the principle of the apparent haptic motionto deliver navigation cues, activating single actuators insequences to give a sensation of continuous motion thatcan be interpreted as directional instructions. We considertwelve different tactile patterns (or signals), provided throughvibrations or "taps". Six of them use one handle, six usetwo handles. The considered signals are illustrated in Fig. 4.Signals involving only one handle (top row) are referred towith "1H", while patterns involving two handles (secondrow) with "2H". The coloured arrows show the pattern ofactivation for each considered signal; their color gradient,from green to red, shows the temporal activation of themotors. For example, signal 1H-1 activates the three motorsacross the handle hold by the user's left hand, stimulating,in sequence, the thumb, the second metacarpal bone (acrossthe purlicue), and finally the index; conversely, signal 1H-2 activates the three motors across the handle hold by theuser's right hand, stimulating, in sequence, the index, thesecond metacarpal bone, and finally the thumb. In bothYOULeftLeft Diag.FrontRight Diag.BackRightSending SignalsComputerSupplyPowerwith ActuatorsHaptic HandlesM5 Stacksa. b. c.Land MarksDirectionalYOULeftLeft Diag.FrontRight Diag.BackRightFig. 3. a) Scheme of the experimental setup. The handles are powered and controlled through an M5 Stacks connected in WiFi with the PC sending thesignals. The handles are used by the participants during the experiment as shown in b) and mounted on the walker as shown in c). b) shows a participantduring an experiment. The participant is facing the illustration of the possible interpretations and orally gives her answers after receiving the directionalcues. c) Focus on the handle mounted on the walker and a participant's hand position.cases, only one handle is active. As an additional example,signal 2H-1 activates the three motors around both handlessimultaneously, stimulating, first, the left thumb and the rightindex, then the second metacarpal bone of both hands, andfinally the left index and right thumb; conversely, signal2H-2 activates, in sequence, the three motors around theright handle and then those on the left handle hold by theuser's left hand (i.e., the difference between 2H-1 and 2H-2lies solely in the motors' temporal activation, shown by thedifferent gradient across the arrows in Fig. 4).There are two groups of stimulations: First, there arethe AHM stimulations around the handle(s), with actuatorspositioned under the tip of the thumb, the second metacarpalbone and the tip of the index finger. Secondly, there are theAHM signals using the actuators positioned along the handle,across the metacarpal bones.3) Type/mode of haptic actuation: vibrations vs. "taps"We consider two different ways of providing haptic cues,vibrations and "taps", delivered by changing the activationmode of the electromagnetic actuators. The tap stimulationconsists of a 220 ms square signal, while the vibrationstimulation consists of 120 Hz sine within a 220 ms squaresignal envelope. For both modes, the signals are precededby a negative impulse pulling the magnets down in the coilbefore pushing it out, so as to give them momentum. Whentwo actuators need to be activated in sequence (see Fig. 4),they are activated with a delay of 110 ms between theirbeginnings, also called the Stimuli Onset Asynchrony (SOA).4) Navigation directionWe asked participants to identify the different signalsof Fig. 4 as directional cues. We considered six possibledirectional interpretations of these signals, presented as di-rectional landmarks in Fig 3.a: left, left diagonal, front,right diagonal, right, and back. As walking backward is lesscommon, we decided to reduce the instructions indicatingsuch movements, not considering back diagonal instructions.These directions are illustrated on the table in front of theparticipant, as shown in Figure 3.b.B. Experimental task and designParticipants are asked to stand behind the walker and holdboth handles as if they were to navigate with it (see Fig 3).While standing in this position, they receive the stimulations.For each stimulation, participants are asked to interpret theperceived motion as one of the possible six directionalinstructions (Sec. III-A.4). After selecting a direction, theyrate their confidence on a 9-point Likert scale. Answers aregiven orally and transcribed by the experimenter.The experiment is divided into six series of stimulations.Each series is composed of thirty-six stimulations, beingthree repetitions of the twelve different signals, presented tothe participant in a randomised order. Each series is deliveredwith the same type of haptic actuation, meaning all thirty-sixstimulations in a series are either vibrating or tapping signals.To prevent participants from becoming accustomed to thestimuli and mitigate learning bias, the type of actuation isalternated. Half of the participants starts the first series withtapping and the other half with vibrations. This experimentalprotocol leads to 12 (signals) x 3 (repetitions) x 3 (se-ries) x 2 (actuation type) = 216 direction identification trialsper participant.C. Participants and experimental procedureParticipants start the experimental session by reading andsigning the consent form, as well as answering demographicquestions about their gender, age, and handedness (the iden-tification of their dominant hand). Finally, they start thedirection identification task detailed in Sec. III-B.We enrolled fourteen participants between 20 and 50 yearsold, four being women, and all being right-handed. Theirdominant hand was determined by the ten-item version ofthe EHI (Edinburgh Handedness Inventory) about their dailyhabits. The participants were naive about the objectives andhypotheses of the study. The experiment lasted one hour.The data collected from the participants were the directionthey perceived ("left", "left diagonal", "front", "right diag-onal", "right", "back", see Fig. 3) and their confidence ratefrom 1 (no confidence at all) to 9 (total certainty). At the endof the experiment, participants also gave open comments andfeedback about the experiment and setup.IV. RESULTSFor a global overview of the data, we generated radargraphs to show the overall tendency in the identification ofdirections, shown in Fig. 5. The radar graphs present thepercentage of answers distribution given by all participantsFig. 4. Directional patterns using the AHM illusion. Each of the six handle pairs represent a stimulation. The top row shows patterns using only onehandle, 1H-* (we greyed out the handle that is not activated), whereas the bottom row shows patterns using both handles, 2H-*. The colored arrows showthe pattern of activation; their colour gradient shows the temporal activation of the motors, green first, then yellow, and finally red. Each motor is activatedfor a period of 220 ms, either for providing a tapping sensation or a vibratory sensation, according to the condition at hand.when receiving a signal, pooling together vibrating and tapsfeedback types. Figs. 5a, b, c, d show these results forpatterns employing AHM towards the left, front, right, andback of the handle(s). For example, from Figs. 5b and d,we can notice that signals 2H-3 and 2H-6 show a cleartendency to be interpreted as directional cues towards the"front" and "back", respectively, with very few alternativeinterpretations. Conversely, signals 1H-3 and 1H-6 havebeen mostly recognised as indicating directional cues eithertowards "front" or "right" and "back" or "right", respectively.In Figs. 5a and c, we can see that interpretations are morevaried. While signals are still mostly recognised as indicatingdirectional cues following the movement of the AHM pattern(i.e., 1H-1, 2H-1, 1H-2, 2H-2 towards the "left"; 1H-4, 2H-4,1H-5, 2H-5 towards the "right"), we registered other inter-pretations, especially involving the diagonal directions whenonly one handle was activated (i.e., 1H-1, 1H-4 towards the"left-diagonal"; 1H-2, 1H-5 towards the "right-diagonal".)Generalised Linear Mixed Model (GLMM): The datawere processed using RStudio software (version 4.3.1). Toassess the impact of the pattern, the fact that the strategywas uni- or bi-manual and actuation type/mode (vibrationvs. tap) on the comprehension of directional information,we employed a Generalised Linear Mixed Model (GLMM).The GLMMs were fitted using maximum likelihood es-timation (Laplace Approximation) with a logit link func-tion and binomial error distribution. The Wald Chi-squaretest (signal, uni/bi-manual, actuation mode) performed onthe GLMM showed a significant effect of the signal sent(2(1) = 11.767, p = 0.001) but no significant effect ofuni-manual vs bi-manual (2(1) = 0.110, p = 0.741) orthe actuation mode (2(1) = 0.102, p = 0.750). For thisstatistical analysis, we assume the presence of correct andwrong answers to have binary data. In order to do that, weconsidered correct: (i) Left or Left Diagonal answers whenconveying AHM patterns moving towards the left of thehandle, (ii) Right or Right Diagonal answers when conveyingAHM moving towards the right, (iii) Front answers for AHMmoving towards the front, and finally (iv) Back answers forAHM moving towards the back (the user).1H-1 2H-1 1H-2 2H-2FrontLeftDiag.LeftRightDiag.RightBackLeft AHM signalsa.b.c.d.1H-3 2H-3 1H-6 2H-6FrontLeftDiag.LeftRightDiag.RightBackFront AHM signals1H-4 2H-4 1H-5 2H-5FrontLeftDiag.LeftRightDiag.RightBackRight AHM signalsFrontLeftDiag.LeftRightDiag.RightBackBack AHM signals1005075250100507525010050752501005075250Fig. 5. Radar graphs showing the user's identification answers based onthe sent signal. a) Signals 1H-1, 2H-1, 1H-2 and 2H-2, using the apparenthaptic motion (AHM) towards the left side of the handle. b) Signals 1H-3and 2H-3, using the AHM towards the front of the handle. c) Signals 1H-4,2H-4, 1H-5, and 2H-5 using the AHM towards the right of the handle. d)Signals 1H-6 and 2H-6, using the AHM towards the back of the handle.The GLMM analysis showed significant difference be-tween the signals success to evoke what we determined asthe good answers. For the following data, you can refer toTable II for p-values and significance. From this analysisit was found that to elicit an instruction of left direction,the signal 1H-1, which uses one handle, is considered betterand significantly different from signal 2H-1 and from signal1H-2. Signal 2H-2, using both handles, is also consideredsignificantly different from signal 2H-1 and from signal 1H-2. Even though the difference between signal 1H-1 and 2H-2is not significant, we can see on Table I that 1H-1 is betterLeft Left Diag. Front Right Diag. Right Back1H-1 48.4 48.8 0.0 0.0 2.8 0.02H-1 43.7 9.5 36.1 2.0 6.7 2.01H-2 44.8 1.2 0.0 36.9 17.1 0.02H-2 59.9 15.1 17.5 3.6 4.0 0.01H-3 0.0 7.1 53.6 8.3 31.0 0.02H-3 0.0 0.0 93.7 0.4 0.8 5.21H-4 19.4 32.9 0.0 1.6 45.6 0.42H-4 6.7 4.4 15.1 17.1 56.7 0.01H-5 15.1 0.4 0.0 44.8 39.7 0.02H-5 13.5 2.0 34.5 10.3 35.3 2.01H-6 0.0 0.0 0.4 8.3 32.1 59.12H-6 0.0 0.0 9.5 0.0 0.0 90.5TABLE IDISTRIBUTION OF ANSWERS (IN %) DEPENDING ON THE SIGNAL SENT.IN GREEN ARE THE ANSWERS TOWARD THE SAME DIRECTION AS THEAHM AND IN ORANGE TOWARD A DIFFERENT DIRECTION.at evoking answers toward the Left or Left Diagonal (1stand 2nd columns in Table I) and almost no contradictoryinterpretations compared to 2H-2 which has 17.5% in Frontanswers (3th column of Table I). Signal 1H-1 with the AHMtowards the left on the left handle thus appears to be thebest pattern to convey a guiding instruction towards the left.Similarly, observations and conclusions can be made for thesignals using the AHM towards the right. Signal 1H-5 usesone handle and is considered better and significantly differentfrom signals 1H-4 and 2H-5. Signal 2H-4 which uses bothhandles is considered better and also significantly differentfrom signals 1H-4 and 2H-5. Even though the differencebetween signal 1H-5 and 2H-4 is not significant, Table Ishows that most of 1H-5 results gather in Right and DiagonalRight (4th and 5th), whereas signal 2H-4 presents highercontradictory interpretations. Signal 1H-5 with the AHMtowards the right on the right handle thus appears to be thebest pattern to convey a guiding instruction towards the left.For the AHM towards the front, we compare the signal1H-3, using one handle on the side of the dominant handwith signal 2H-3 made of two AHM elicited on both handlessimultaneously. Just as Fig. 5 shows, the GLMM indicatessignificant difference and better performance of signal 2H-3 over 1H-3 see Table II. Signal 2H-3 gathers 93.7% ofanswers in the Front answer (Table I). Finally, For the AHMtowards the back, we compare the signal 1H-6, using onehandle on the side of the dominant hand with signal 2H-6made of two AHM elicited on both handles simultaneously.The GLMM validates the first observations on Fig. 5 andindicates significant difference and better performance of sig-nal 2H-6 (90.5% success Table I) over signal 1H-6 (59.1%).Wilcoxon repeated-measures analysis: In the GLMMmodel, we saw the effect of the signal on the interpretationof the direction, highlighting the optimal patterns to use toindicate left, right, front and back directions. We performeda Wilcoxon repeated-measures post-hoc analysis betweenall the six possible answers of all twelve signals (180tests) showing a significant effect of the signals on theinterpretations. The post-hoc analysis also confirm the ab-sence of significant effect of the mode on the interpretation,with equivalent performances and interpretations for bothvibrations and tap signals.TABLE IIExperimental evaluationConditions Active handlesActive handles1H (one handle), 2H (two handles)AHM stimuliAHM stimulisix ways of providing AHM stimuli towards theleft (), bottom (), right (), or top () sideof the handle (see Fig. 4)Statistical analysis: direction identificationComparisons for signals with AHM cues in the same direction1H-1 vs 2H-1 p = 0.002 1H-1 vs 1H-2 p &amp;lt; 0.0011H-1 vs 2H-2 p = 0.471 2H-2 vs 2H-1 p = 0.0012H-2 vs 1H-2 p &amp;lt; 0.001 1H-3 vs 2H-3 p = 0.0021H-5 vs 2H-4 p = 0.569 1H-5 vs 1H-4 p &amp;lt; 0.0011H-5 vs 2H-5 p &amp;lt; 0.001 2H-4 vs 1H-4 p &amp;lt; 0.0012H-4 vs 2H-5 p &amp;lt; 0.001 1H-6 vs 2H-6 p = 0.019</body>
	<conclusion>This work aimed to assess the effectiveness of differentpatterns in conveying directional information through theApparent Haptic Motion Illusion (AHM), with the objectiveof developing rich navigation techniques for mobility aid sys-tems, such as a walker. We enrolled fourteen participants in ahuman-subjects experiment to evaluate the haptic perceptionof directional cues conveyed through two handles attached ona walker. We investigated three key elements: the differencebetween uni-manual and bi-manual guiding strategies, andthe identification of the most effective tactile patterns andactuation modality for navigation assistance. For this study,we designed a haptic handle with five custom electromag-netic actuators, able to give sensations of movement in fourdirections through the AHM illusion on the hand.The results of the study are promising, highlighting severalkey findings: The study identified specific patterns that werehighly effective in conveying directional instructions towardsthe front (93.7%), the back (90.5%), the left ((Left = 48.4%)+ (Left Diagonal = 48.8%) = 97.2%), and the right ((Right= 39.7%) + (Righ Diagonal = 44.8%) = 84.5%). The studyalso identified cases where participants' interpretations weredivided, often influenced by the side of the stimulated handlevs. the direction of the AHM moving pattern. The result andstatistical analysis showed no significant difference betweenusing vibratory vs. tapping modes for conveying directionalcues. Because there was also no significant difference in-duced by providing vibrotactile cues on one or two handles,the guiding strategy can be adapted to both uni-manualand bi-manual setups and assistive devices. This adaptabilitymakes the technology suitable for various mobility aids, suchas white canes, power wheelchairs, walkers and precanes.This research wishes to contribute to the development ofassistive devices enhancing the autonomy and safety ofpeople with sensory impairments.In future works, the aim will be to help users on a walkerfollow complex trajectories by using tactile instructions.</conclusion>
	<discussion>We conducted experiments with fourteen participants, whoreceived signals on one or two handles with either vibrationsor taps. They provided responses based on the directioncue they perceived. Our analysis focused on determiningwhich stimulation mode, rendering pattern, and number ofactive handles is best for providing navigation assistance ona walker.Left/Right Direction: Signal 1H-1, which employed a sin-gle handle, was more effective at conveying a "left" directioncue compared to other signals using the AHM towards theleft. This is shown by the combination of Left and DiagonalLeft, with less than 3% of alternate response. It is true that2H-2 has more answers on the Left axis, but it also engenderscontradictory interpretations with more than 15% of answerson the Front axis. Similarly for the right side, Signal 1H-5, using a single handle, outperformed signals 1H-4, 2H-4,and 2H-5. This result suggests that a single-handle patternwith the AHM towards the left on the left handle or anAHM towards the right on the right handle emerged as themost effective pattern for side instructions. Signals 2H-2 and2H-4, however lightly less efficient, are a good two-handlealternatives to elicit such navigational instructions. Withouta learning phase, we see here that the duality of informationfor left/right instructions can be misleading.Front/Back Direction: Signals 2H-3 and 2H-3, conveyingthe AHM cues along both handles simultaneously towards,respectively, the front and the back, demonstrated superiorperformance in conveying the desired directional cues com-pared to signals 1H-3 and 1H-6. This result suggests that apattern involving simultaneous activation of both handles wasmore effective in that case, as the presence of two identicalinformation seems to reinforce the information of front/back.On Fig. 5.b and d, we can also notice an ambiguity leadingto some alternate interpretation on the single handle answers(in blue). Those mislead interpretations mainly gathered onthe Right axis. We interpret this artefact as a consequenceof the use of the dominant hand for the Signals 1H-3 and1H-6 all on the right handle as all the participants were righthanded.It also appears that for the signals 1H-2 and 1H-4 respec-tively on Fig. 5.a and b and Table I, we can clearly see thatthe interpretation is split in two main groups, which are theside of the AHM direction and the opposite direction. Theconfusion here seems to come from the fact that the motionindicates one direction different from the side of the activatedhandle. For example, signal 1H-2 is an AHM towards the leftside but conveyed onto the right hand.We found no significant difference between using one or twohandles and between vibrations vs. taps actuation modalitiesto deliver the target navigation information. These resultsmean that, first, the guiding strategy can be employed withlimited hardware, on a single handle, which is easier to adaptto other mobility assistance devices that only have one hold-able end-effector, such as white canes or power wheelchair.Two-handles can be used in some cases to reinforce theinformation, depending on the user's preference. Similarly,as no actuation mode was found better than the other, itcan be chosen according to the user preference as well asthe capabilities of the considered haptic actuation system.Overall, our findings revealed that the AHM paradigm canbe used to provide rich directional cues.</discussion>
	<biblio>[1] J. Dammeyer, "Mental and behavioral disorders among people withcongenital deafblindness," Research in developmental disabilities,vol. 32, 2011.[2] ----, "Deafblindness: A review of the literature," Scandinavian J. ofpublic health, vol. 42, 2014.[3] A. E. N. Hoover et al., "Sensory compensation in sound localizationin people with one eye," Experimental Brain Research, vol. 216, 2012.[4] M. Bergman, "Rehabilitating Blind Persons with Impaired Hearing,"J. of Visual Impairment &amp; Blindness, vol. 53, 1959.[5] L. Kay, "The Sonicguide Long Cane, and Dog Guide: Their Compat-ibility," J. of Visual Impairment &amp; Blindness, vol. 74, 1980.[6] J. M. Benjamin, Jr. and N. A. Ali, "An Improved Laser Cane For TheBlind," in Proc. of SPIE, San Diego, 1974.[7] S. Gallo et al., "Augmented white cane with multimodal hapticfeedback," in Proc. IEEE RAS EMBS BioRob, 2010.[8] T. Amemiya and H. Gomi, "Buru-Navi3: behavioral navigations usingillusory pulled sensation created by thumb-sized vibrator," in Proc.SIGGRAPH 2014 Emerging Technologies, 2014.[9] A. J. Spiers and A. M. Dollar, "Design and Evaluation of Shape-Changing Haptic Interfaces for Pedestrian Navigation Assistance,"IEEE Trans. on Haptics, 2017.[10] A. J. Spiers et al., "The S-BAN: Insights into the Perception of Shape-Changing Haptic Interfaces via Virtual Pedestrian Navigation," ACMTrans. on Computer-Human Interaction, 2022.[11] L. Devigne et al., "Power Wheelchair Navigation Assistance UsingWearable Vibrotactile Haptics," IEEE Trans. on Haptics, 2020.[12] L. V. Boas et al., "Auditory processing performance in blind people,"Brazilian J. of Otorhinolaryngology, vol. 77, 2011.[13] A. M. Kappers, M. F. S. Oen, T. J. Junggeburth, and M. A. Plaisier,"Hand-held Haptic Navigation Devices for Actual Walking," IEEETrans. on Haptics, 2022.[14] L. Kuang, M. Marchal, P. R. Giordano, and C. Pacchierotti, "Rollinghandle for hand motion guidance and teleoperation," in Proc. Euro-Haptics, 2022.[15] F. Chinello, C. Pacchierotti, J. Bimbo, N. G. Tsagarakis, and D. Prat-tichizzo, "Design and evaluation of a wearable skin stretch device forhaptic guidance," IEEE RA-L, pp. 524-531, 2017.[16] G. Liu et al., "Tactile Compass: Enabling Visually Impaired Peopleto Follow a Path with Continuous Directional Feedback," in Proc. ofCHI, 2021.[17] L. Kuang et al., "Wearable cutaneous device for applying posi-tion/location haptic feedback in navigation applications," in Proc.IEEE HAPTICS, 2022.[18] A. Wachaja et al., "Navigating blind people with walking impairmentsusing a smart walker," Autonomous Robots, 2017.[19] J. B. Van Erp, "Guidelines for the use of vibro-tactile displays inhuman computer interaction," in Proc. of EuroHaptics. Citeseer, 2002.[20] A. Israr and I. Poupyrev, "Control space of apparent haptic motion,"in Proc. IEEE World Haptics Conference, 2011.[21] S. Zhao et al., "Intermanual apparent tactile motion on handheldtablets," in Proc. IEEE World Haptics Conference, 2015.[22] Lederman and Jones, "Tactile and Haptic Illusions." IEEE Trans. onHaptics, 2011.[23] C. E. Sherrick and R. Rogers, "Apparent haptic movement," Perception&amp; Psychophysics, vol. 1, no. 6, 1966.[24] I. Lacote et al., ""Tap Stimulation": an Alternative to Vibrationsto Convey the Apparent Haptic Motion Illusion," in Proc. IEEEHAPTICS, 2022.[25] ----, "Investigating the Haptic Perception of Directional InformationWithin a Handle," IEEE Trans. on Haptics, 2023.[26] B. Duvernoy et al., "Hapticomm: A touch-mediated communicationdevice for deafblind individuals," IEEE RA-L, vol. 8, no. 4, 2023.[27] I. Lacote et al., "Speed Discrimination in the Apparent Haptic MotionIllusion," in Proc. EuroHaptics, 2022.</biblio>
</article>