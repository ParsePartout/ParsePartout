<article>
	<preamble>Iria_Juan-Manuel_Gerardo.pdf</preamble>
	<title>On the Development of the RST Spanish Treebank</title>
	<auteurs>
		<auteur>
			<name>Iria da Cunha Institute</name>
			<mail>iria.dacunha@upf.edu</mail>
            <affiliation>for Applied Linguistics (UPF), Spain Instituto de Ingenieria (UNAM), Mexico Laboratoire Informatique d'Avignon (UAPV), France</affiliation>
      </auteur>
		<auteur>
			<name>Juan-Manuel Torres-Moreno Laboratoire</name>
			<mail>juan-manuel.torres@univavignon.fr</mail>
            <affiliation>Informatique d'Avignon (UAPV), France</affiliation>
      </auteur>
		<auteur>
			<name>Gerardo Sierra Instituto</name>
			<mail>gsierram@iingen.unam</mail>
            <affiliation>Instituto de Ingenieria (UNAM), Mexico</affiliation>
      </auteur>
	</auteurs>
	<abstract>
	In this article we present the RST Spanish Treebank, the first corpus annotated with rhetorical relations for this language. We describe the characteristics of the corpus, the annotation criteria, the annotation procedure, the inter-annotator agreement, and other related aspects. Moreover, we show the interface that we have developed to carry out searches over the corpus' annotated texts.
	</abstract>
	<introduction>
	The Rhetorical Structure Theory (RST) (Mann andThompson, 1988) is a language independent theorybased on the idea that a text can be segmented intoElementary Discourse Units (EDUs) linked bymeans of nucleus-satellite or multinuclearrhetorical relations. In the first case, the satellitegives additional information about the other one,the nucleus, on which it depends (ex. Result,Condition, Elaboration or Concession). In thesecond case, several elements, all nuclei, areconnected at the same level, that is, there are noelements dependent on others and they all have thesame importance with regard to the intentions ofthe author of the text (ex. Contrast, List, Joint orSequence). The rhetorical analysis of a text bymeans of RST includes 3 phases: segmentation,detection of relations and building of hierarchicalrhetorical trees. For more information about RSTwe recommend the original article of Mann andThompson (1988), the web site of RST1 and theRST review by Taboada and Mann (2006a).RST has been used to develop severalapplications, like automatic summarization,information extraction (IE), text generation,question-answering, automatic translation, etc.(Taboada and Mann, 2006b). Nevertheless, most ofthese works have been developed for English,German or Portuguese. This is due to the fact thatat present corpora annotated with RST relations areavailable only for these languages (for English:Carlson et al., 2002, Taboada and Renkema, 2008;for German: Stede, 2004; for Portuguese: Pardo etal., 2008) and there are automatic RST parsers fortwo of them (for English: Marcu, 2000; forPortuguese: Pardo et al., 2008) or automatic RSTsegmenters (for English: Tofiloski et al., 2009).Scientific community working on RST applied toSpanish is very small. For example, Bouayad-Aghaet al. (2006) apply RST to text generation inseveral languages, Spanish among them. Da Cunhaet al. (2007) develop a summarization system formedical texts in Spanish based on RST. Da Cunhaand Iruskieta (2010) perform a contrastive analysisof Spanish and Basque texts. Romera (2004)analyzes coherence relations by means of RST inspoken Spanish. Taboada (2004) applies RST toanalyze the resources used by speakers to elaborateconversations in English and Spanish.We consider that it is necessary to build aSpanish corpus annotated by means of RST. Thiscorpus should be useful for the development of arhetorical parser for this language and several otherapplications related to computational linguistics,like those developed for other languages1 http://www.sfu.ca/rst/index.html1(automatic translation, automatic summarization,IE, etc.). And that is what we pretend to achievewith our work. We present the development of theRST Spanish Treebank, the first Spanish corpusannotated by means of RST.In Section 2, we present the state of the artabout RST annotated corpora. In Section 3, weexplain the characteristics of the RST SpanishTreebank. In Section 4, we show the searchinterface we have developed. In Section 5, weestablish some conclusions and future work.
	</introduction>
	<corps>
	2 State of the ArtThe most known RST corpus is the RST DiscourseTreebank, for English (Carlson et al., 2002a,2002b). It includes 385 texts of the journalisticdomain, extracted from the Penn Treebank(Marcus et al., 1993), such as cultural reviews,editorials, economy articles, etc. 347 texts are usedas a learning corpus and 38 texts are used as a testcorpus. It contains 176,389 words and 21,789EDUs. 13.8% of the texts (that is, 53) wereannotated by two people with a list of 78 relations.For annotation, the annotation tool RSTtool 2(O'Donnell, 2000) was used, with someadaptations. The principal advantages of thiscorpus stand on the high number of annotated texts(for the moment it is the biggest RST corpus) andthe clarity of the annotation method (specified inthe annotation manual by Carlson and Marcu,2001). However, some drawbacks remain. Thecorpus is not free, it is not on-line and it onlyincludes texts of one domain (journalistic).For English there is also the DiscourseRelations Reference Corpus (Taboada andRenkema, 2008). This corpus includes 65 texts(each one tagged by one annotator) of several typesand from several sources: 21 articles from the WallStreet Journal extracted from the RST DiscourseTreebank, 30 movies and books' reviews extractedfrom the epinions.com website, and 14 diversetexts, including letters, webs, magazine articles,newspaper editorials, etc. The tool used forannotation was also the RSTtool. The advantagesof this corpus are that it is free and on-line, and itincludes texts of several types and domains. Thedisadvantages are that the amount of texts is notvery high, the annotation methodology is not2 http://www.wagsoft.com/RSTTool/specified and it does not include texts annotated byseveral people.Another well-known corpus is the PotsdamCommentary Corpus, for German (Stede, 2004;Reitter and Stede, 2003). This corpus includes 173texts on politics from the on-line newspaperMarkische Allgemeine Zeitung. It contains 32,962words and 2,195 sentences. It is annotated withseveral data: morphology, syntax, rhetoricalstructure, connectors, correference and informativestructure. Nevertheless, only a part of this corpus(10 texts), which the authors name "core corpus",is annotated with all this information. The textswere annotated with the RSTtool. This corpus hasseveral advantages: it is annotated at differentlevels (the annotation of connectors is especiallyinteresting); all the texts were annotated by twopeople (with a previous RST training phase); it isfree for research purposes, and there is a tool forsearching over the corpus (although it is notavailable on-line). The disadvantages are: thegenre and domain of all the texts are the same, themethodology of annotation was quite intuitive(without a manual or specific criteria) and theinter-annotator agreement is not given.For Portuguese, there are 2 corpora, built inorder to develop a rhetorical parser (Pardo et al.,2008). The first one, the CorpusTCC (Pardo et al.,2008), was used as learning corpus for detection oflinguistic patterns indicating rhetorical relations. Itcontains 100 introduction sections of computerscience theses (53,000 words and 1,350 sentences).To annotate the corpus a list of 32 rhetoricalrelations was used. The annotation manual byCarlson and Marcu (2001) was adapted toPortuguese. The annotation tool was the ISI RSTAnnotation Tool3 , an extension of the RSTtool.The advantages of this corpus are: it is free, itcontains an acceptable number of texts and wordsand it follows a specific annotation methodology.The disadvantage is: it only includes texts of onegenre and domain, only annotated by one person.The second one, Rhetalho (Pardo and Seno,2005), was used as reference corpus for the parserevaluation. It contains 50 texts: 20 introductionsections and 10 conclusion sections from computerscience scientific articles, and 20 texts from the on-line newspaper Folha de Sao Paulo (7 from theDaily section, 7 from the World section and 6 from3 http://www.isi.edu/~marcu/discourse/2the Science section). It includes approximately5,000 words. The relations and the annotation toolare the same as those used in the CorpusTCC. Theadvantages of this corpus are that it is free, it wasannotated by 2 people (they both were RST expertsand followed an annotation manual) and it containstexts of several genres and domains. The maindisadvantage is the scarce amount of texts.The Penn Discourse Treebank (Rashmi et al.,2008)f for English includes texts annotated withinformation related to discourse structure andsemantics (without a specific theoretical approach).Its advantages are: its big size (it contains 40,600annotated discourse relations) allows to applymachine learning, and the discourse annotationsare aligned with the syntactic constituencyannotations of the Penn Treebank. Its limitationsare: dependencies across relations are not marked,it only includes texts of the journalistic domain,and it is not free. Although there are severalcorpora annotated with discourse relations, there isnot a corpus of this type for Spanish.3 The RST Spanish TreebankAs Sierra (2008) states, a corpus consists of acompilation of a set of written and/or spoken textssharing some characteristics, created for certaininvestigation purposes. According to Hovy (2010),we use 7 core questions in corpus design, detailedin the next subsections.3.1 Selecting a CorpusFor the RST Spanish Treebank, we wanted toinclude short texts (finally, the average is 197words by text; the longest containing 1,051 wordsand the shortest, 25) in order to get a best on-linevisualization of the RST trees. Moreover, in thefirst stage of the project, we preferred to selectspecialized texts of very different areas, althoughin the future we plan to include also non-specialized texts (ex. blogs, news, websites) inorder to guarantee the representativity of thecorpus. We did not find a pre-existing Spanishcorpus with these characteristics, so we decided tobuild our own corpus. Following Cabre (1999), weconsider that a text is specialized if it is written bya professional in a given domain. According to thiswork, specialized texts can be divided in threelevels: high (both the author and the potentialreader of the text are specialists), average (theauthor of the text is a specialist, and the potentialreader of that text is a student or someoneinterested in or possessing some prior knowledgeabout the subject) and low (the author of the text isa specialist, and the potential reader is the generalpublic). The RST Spanish Treebank includesspecialized texts of the three mentioned levels:high (scientific articles, conference proceedings,doctoral theses, etc.), average (textbooks) and low(articles and reports from popular magazines,associations' websites, etc.). The texts have beendivided in 9 domains (some of them includingsubdivisions): Astrophysics, EarthquakeEngineering, Economy, Law, Linguistics (AppliedLinguistics, Language Acquisition, PLN,Terminology), Mathematics (Primary Education,Secondary Education, Scientific Articles),Medicine (Administration of Health Services,Oncology, Orthopedy), Psychology and Sexuality(Clinical Perspective, Psychological Perspective).The size of a corpus is also a polemic question.If the corpus is developed for machine learning, itssize will be enough when the application we wantto develop obtains acceptable percentages ofprecision and recall (in the context of thatapplication). Nevertheless, if the corpus is builtwith descriptive purposes, it is difficult todetermine the corpus size. In the case of a corpusannotated with rhetorical relations, it is even moredifficult, because there are various factorsinvolved: EDUs, SPANs (that is, a group of relatedEDUs), nuclearity and relations. In addition,relations are multiple (we use 28). As Hovy (2010:13) mentions, one of the most difficult phenomenato annotate is the discourse structure. Our corpuscontains 52,746 words and 267 texts. Table 1includes RST Spanish Treebank statistics in termsof texts, words, sentences and EDUs.Texts Words Sentences EDUsLearning corpus 183 41,555 1,759 2,655Test corpus 84 11,191 497 694Total corpus 267 52,746 2,256 3,349Table 1: RST Spanish Treebank statisticsTo increase the linear performance of astatistical method, it is necessary that the trainingcorpus size grows exponentially (Zhao et al.,2010). However, the RST Spanish Treebank is notdesigned only to use statistical methods; we thinkit will be useful to employ symbolic or hybrid3algorithms (combining symbolic and statisticalmethods). Moreover, this corpus will be dynamic,so we expect to have a bigger corpus in the future,useful to apply machine learning methods.If we measure the corpus size in terms of wordsor texts, we can take as a reference the other RSTcorpora. Nevertheless, as Sierra states (2008), it is"absurd" to try to build an exhaustive corpuscovering all the aspects of a language. On thecontrary, the linguist looks for therepresentativeness of the texts, that is, tries tocreate a sample of the studied language, selectingexamples which represent the linguistic reality, inorder to analyze them in a pertinent way. In thissense and in the frame of this work, we considerthat the size will be adequate if the rhetorical treesof the corpus include a representative number ofexamples of rhetorical relations, at least 20examples of each one (taking into account that thecorpus contains 3115 relations, we consider thatthis quantity is acceptable; however, we expect tohave even more examples when the corpus grows).Table 2 shows the number of examples of eachrelation currently included into the RST SpanishTreebank (N-S: nucleus-satellite relation; N-N:multinuclear relation). As it can be observed, itcontains more than 20 examples of most of therelations. The exceptions are the nucleus-satelliterelations of Enablement, Evaluation, Summary,Otherwise and Unless, and the multinuclearrelations of Conjunction and Disjunction, becauseit is not so usual to find these rhetorical relations inthe language, in comparison with others. Hovy(2010: 128) states that, given the lack of examplesin the corpus, there are 2 possible strategies: a) toleave the corpus as it is, with few or no examplesof some cases (but the problem will be the lack oftraining examples for machine learning systems),or b) to add low-frequency examples artificially to"enrich" the corpus (but the problem will be thedistortion of the native frequency distribution andperhaps the confusion of machine learningsystems). In the current state of our project, wehave chosen the first option. We think that,including specialized texts in a second stage, wewill get more examples of these less commonrelations. If we carry out a more granulatedsegmentation maybe we could obtain moreexamples; however, we wanted to employ thesegmentation criteria used to develop the SpanishRST discourse segmenter (da Cunha et al., 2011).QuantityRelation TypeN %Elaboration N-S 765 24.56Preparation N-S 475 15.25Background N-S 204 6.55Result N-S 193 6.20Means N-S 175 5.62List N-N 172 5.52Joint N-N 160 5.14Circumstance N-S 140 4.49Purpose N-S 122 3.92Interpretation N-S 88 2.83Antithesis N-S 80 2.57Cause N-S 77 2.47Sequency N-N 74 2.38Evidence N-S 59 1.89Contrast N-N 58 1.86Condition N-S 53 1.70Concession N-S 50 1.61Justification N-S 39 1.25Solution N-S 32 1.03Motivation N-S 28 0.90Reformulation N-S 22 0.71Otherwise N-S 3 0.10Conjunction N-N 11 0.35Evaluation N-S 11 0.35Disjunction N-N 9 0.29Summary N-S 8 0.26Enablement N-S 5 0.16Unless N-S 2 0.06Table 2: Rhetorical relations in RST Spanish Treebank3.2 Instantiating the TheoryOur segmentation and annotation criteria are verysimilar to the original ones used by Mann andThompson (1988) for English, and by da Cunhaand Iruskieta (2010) for Spanish. We also explorethe annotation manual for English by Carlon andMarcu (2001). Though we use some of theirpostulates, we think that their analysis is toometiculous in some aspects. Because of this, weconsider that it is not adjusted to our interest,which is the finding of the simplest and mostobjective annotation method, orientated to the4future development of a rhetorical parser forSpanish. To sum up, our segmentation criteria are:a) All the sentences of the text are segmented asEDUs (we consider that a sentence is a textualpassage between a period and another period, asemicolon, a question mark or an exclamationpoint; texts' titles are also segmented). Exs.4[Estas son las razones fundamentales que motivaroneste trabajo.][These are the fundamental reasons which motivated thiswork.][Estudio de caso unico sobre violencia conyugal][Study of a case on conjugal violence]b) Intra-sentence EDUs are segmented, using thefollowing criteria:b1) An intra-sentence EDU has to include a finiteverb, an infinitive or a gerund. Ex.[Siendo una variante de la eliminacion Gaussiana,][posee caracteristicas didacticas ventajosas.][Being a variant of Gaussian elimination,] [it possessesdidactic profitable characteristics.]b2) Subject/object subordinate clauses orsubstantive sentences are not segmented. Ex.[Se muestra que el modelo discreto en diferencias finitases convergente y que su realizacion se reduce a resolveruna sucesion de sistemas lineales tridiagonales.][It appears that the discreet model in finite differences isconvergent and that its accomplishment is to solve asuccession of tridiagonal linear systems.]b3) Subordinate relative clauses are not segmented.Ex.[Durante el proceso, que utiliza solo aritmetica entera,se obtiene el determinante de la matriz de coeficientesdel sistema, sin necesidad de calculos adicionales.][During the process, which only uses entire arithmetic, thedeterminant of the system coefficient matrix is obtained,without additional calculations.]b4) Elements in parentheses are only segmented ifthey follow the criterion b1. Ex.[Este ano se cumple el bicentenario del nacimiento deNiels (Nicolas, en nuestro idioma) Henrik Abel.][This year is the bicentenary of Niels's birth (Nicolas, inour language) Henrik Abel.]b5) Embedded units are segmented by means ofthe non-relation Same-Unit proposed by Carlonand Marcu (2001). Figure 1 shows this structure.[En decadas precedentes se ha puesto de manifiesto,] [yasi lo han atestiguado muchos investigadores de la4 Spanish examples were extracted from the corpus. Englishtranslations are ours.terminologia cientifica serbia,] [una tendencia aimportar prestamos del ingles.][In previous decades it has been shown,] [and it has beentestified by many researchers of the scientific Serbianterminology,] [a trend to import loanwords from English.]Figure 1: Example of the non-relation Same-Unit3.3 Designing the InterfaceThe annotation tool used in this work is theRSTtool, since it is free and easy to use. Therefore,we preferred to use it instead of designing a newone. Nevertheless, we have designed an on-lineinterface to include the corpus and to carry outsearches over it (see Section 4).3.4 Selecting and Training the AnnotatorsWith regard to the corpus annotators, we have ateam of 10 people (last year Bachelor's degreestudents, Master's degree students and PhDs) 5 .Before the annotation, they took a RST course of 6months (100 hours), where the segmentation andannotation methodology used for the developmentof the RST Spanish Treebank was explained.6 Wecalled this period "training phase". The course hada theoretical and a practical part. In the theoreticalpart, some criteria with regard to the 3 phases ofrhetorical analysis (segmentation, detection ofrelations, and rhetorical trees building) were givento annotators. In the practical part, firstly, it wasexplained how to use the RSTtool. Secondly,annotators extracted several texts from the web,following their personal interests, as for example,music, video games, cookery or art webs. Theysegmented those texts, using the establishedsegmentation criteria. Once segmented, all thedoubts and problematic examples were discussed,and they tried to get an agreement on the mostcomplicated cases. Thirdly, the relations were5 We thank annotators (Adriana Valerio, Brenda Castro,Daniel Rodriguez, Ita Cruz, Jessica Mendez, Josue Careaga,Luis Cabrera, Marina Fomicheva and Paulina De La Vega)and interface developers (Luis Cabrera and Juan Rolland).6 This course was given in the framework of a last-year subjectin the Spanish Linguistics Degree at UNAM (Mexico City).5analyzed (using a given relations list) and, onceagain, annotators discussed the difficult cases.After the discussion, texts were re-annotated toverify if the difficulties were solved. This processwas doubly interesting, since it helped to createcommon criteria for the annotation of the finalcorpus and to define the annotation criteria moreclearly and consensually, in order to include themin the RST Spanish Treebank annotation manual.Once annotators agreed on the most difficult cases,we consider that the training phase finished.3.5 Designing and Managing the AnnotationProcedureWe start from the following annotation definition:Annotation (`tagging') is the process of adding newinformation into source material by humans(annotators) or suitably trained machines. [...]. Theaddition process usually requires some sort ofmental decision that depends both on the sourcematerial and on some theory or knowledge that theannotator has internalized earlier. (Hovy, 2010: 6)Exactly, after our annotators internalized thetheory and annotation criteria during the trainingphase, the "annotation phase" of the final textsincluded in the RST Spanish Treebank started. Inthis phase, the annotation tasks were assigned toannotators (the number of texts assigned to eachannotator was different, depending on theiravailability). They were asked to carry out theannotation individually and without questionsamong them. We calculated that the average timeto carry out the annotation of one text was between15 minutes and 1 hour. This time difference is dueto the fact that the corpus includes both short andlong texts. The annotation process is the following:once a text is segmented, rhetorical relationsbetween EDUs are annotated. First, EDUs insidethe same sentence are annotated in a binary way.Second, sentences inside the same paragraph arelinked. Finally, paragraphs are linked.Hovy (2010) states that it is difficult todetermine if, for the same money (we add "for thesame time"), it is better to double-annotate less, orto single-annotate more. As he explains, Dligach etal. (2010) made an experiment with OntoNotes(Pradhan et al., 2007) verb sense annotation. Theresult was that, assuming the annotation is stable(that is, inter-annotator agreement is high), it isbetter to annotate more, even with only oneannotator. The problem with RST annotation isthat there are so many categories to annotate, thatis very difficult to obtain a stable annotation.Therefore, we consider it is necessary to have atleast some texts double-annotated (or even triple-annotated), in order to have an adequate discoursecorpus. This is the reason why, following the RSTDiscourse Treebank methodology, we use sometexts as learning corpus and some others (from theMathematics, Psychology and Sexuality domains)as test corpus: 69% (183 texts) and 31% (84 texts),respectively. The texts of the learning corpus wereannotated by 1 person, whereas the texts of the testcorpus were annotated by 2 people.3.6 Validating ResultsDa Cunha and Iruskieta (2010) measure inter-annotator agreement by using the RST treescomparison methodology by Marcu (2000). Thismethodology evaluates the agreement on 4elements (EDUs, SPANs, Nuclearity andRelations), by means of precision and recallmeasures (an annotation with regard to the otherone). Following this methodology, we havemeasured inter-annotator agreement over the testcorpus. We employ an on-line automatic tool forRST trees comparison, RSTeval (Mazeiro andPardo, 2009), where Marcu's methodology hasbeen implemented (for 4 languages: English,Portuguese, Spanish and Basque). We know thatthere are some other ways to measure agreement,such as Cohen's kappa (Cohen, 1960) or Fleiss'skappa (Fleiss, 1971), for example. Nevertheless,we consider that Marcu's methodology (2000) issuitable to compare adequately 2 annotations of thesame original text, because it has been designedspecifically for this task.For each trees pair from the test corpus,precision and recall were measured separately.Afterwards, all those individual results were puttogether to obtain general results. Table 3 showsglobal results for the 4 categories. The categorywith more agreement was EDUs (recall: 91.04% /precision: 87.20%), that is, segmentation. Thisresult was expected, since the segmentation criteriagiven to the annotators were quite precise and thepossibility of mistake was low. The lowestagreement was obtained for the category Relations(recall: 78.48% / precision: 76.81%). This result islower than the other, but we think it is acceptable.In the RST Discourse Treebank the trend wassimilar to the one detected in our corpus: the6highest agreement is obtained at the segmentationlevel and the lowest at the relations level.Category Precision RecallEDUs 87.20% 91.04%SPANs 86% 87.31%Nuclearity 82.46% 84.66%Relations 76.81% 78.48%Table 3: Inter-annotator agreementPrecision and recall have not been calculatedwith respect to a gold standard because it does notexist for Spanish. Our future aim is to reach aconsensus on the annotation of the test corpus(using an external "judge"), in order to establish aset of texts considered as a preliminary goldstandard for this language. We consider that theannotations have quality at present, because inter-annotator agreement is quite high; however, thisconsensus could solve the typical annotationmistakes we have detected or some ambiguities.We have analyzed the main discrepancy reasonsbetween annotators. With regard to thesegmentation, the main one was human mistake;ex. segmenting EDUs without a verb (oneannotator segmented the following passage into 2EDUs because she detected a Means relation, butthe second EDU does not include any verb):[Ademas estudiamos el desarrollo de criterios paradeterminar si un semigrupo dado tiene dicha propiedad ][mediante el estudio de desigualdades de curvatura-dimension. ][We also study the development of tests in order todetermine if a given semi group has this property] [by meansof curvature-dimension inequalities.]The second reason was that in the manual someaspects were not explained in detail. For example,if a substantive sentence or a direct/object clause(which must not be segmented, according to thepoint b2) includes two coordinated clauses, thesemust not be segmented either. Thus, we foundsome erroneous segmentations. For example:[Los hombres adultos tienen miedo de fracasar] [y nocumplir con el rol masculino de ser proveedores delhogar y de proteger a su familia.][Adult men are scared to fail] [and not to fulfill themasculine role of being the suppliers of the home and toprotect their family.]This kind of mistakes allowed us to refine oursegmentation manual a posteriori. In the future, wewill ask the test corpus annotators to make a newannotation of the texts, using the refined manual, inorder to check if the agreement increases, in thesame way as the RST Discourse Treebank.With regard to rhetorical annotations, wedetected 2 main reasons of inter-annotatordisagreement. The first one was the ambiguity ofsome relations and their corresponding connectors;for example, Justification-Reason, Antithesis-Concession or Circumstance-Means relations, likein the following passage (in Spanish, "al" mayindicate time or manner):[Los ninos aprenden matematicas] [al resolverproblemas.][Children learn mathematics] [when solving problems.]The second one is due to differences betweenannotators when determining nuclearity. Forexample, in the following passage, one annotatormarked Background and the other one Elaboration:[Quedo un hueco en la pared de 60 x1.20cm.]S_Background [Norma y Andres quierencolocar en el hueco una pecera. ]N_Background[Quedo un hueco en la pared de 60 x1.20cm.]N_Elaboration [Norma y Andres quierencolocar en el hueco una pecera. ]S_Elaboration[A hole of 60 x 1.20 cm remained in the wall.] [Norma andAndres want to place a fish tank in the hole.]It is easier to solve segmentation disagreementthan relations disagreement, since in this caseannotator subjectivity is more evident; we mustconsider how to refine our manual in this sense.3.7 Delivering and Maintaining the ProductHovy (2010) mentions some technical issuesregarding these points: licensing, distribution,maintenance and updates. With regard to licensingand distribution, the RST Spanish Treebank will befree for research purposes. We have a datamanager responsible for maintenance and updates.The description of the annotated corpus is alsoa very important issue (Ide and Pustejovsky, 2010).It is important to provide a high level descriptionof the corpus, including the theoretical framework,the methodology (annotators, annotation manualand tool, agreement, etc.), the means for resourcemaintenance, the technical aspects, the projectleader, the contact, the team, etc. The RST SpanishTreebank includes all this detailed information.XML (with a DTD) has been used, in order thecorpus can be reused for several aplications. In thefuture, we plan to use the standard XCES.7To know more about resources development,linguistic annotation or inter-annotator agreement,we recommend: Palmer et al. (on-line), Palmer andXue (2010), and Artstein and Poesio (2008).4 The Search Interface of the RSTSpanish TreebankThe RST Spanish Treebank interface is freelyavailable on-line7. It allows the visualization anddownloading of all the texts in txt format, withtheir corresponding annotated trees in RSTtoolformat (rs3), as well as in image format (jpg). Eachtext includes its title, its reference, its web link (ifit is an on-line text) and its number of words. Theinterface shows texts by areas and allows the userto select a subcorpus (including individual files orfolders containing several files). The selectedsubcorpus can be saved on local disk (generating axml file) for future analyses.The interface includes a statistical tool whichallows obtaining statistics of rhetorical relations ina subcorpus selected by the user. The RSTtool alsooffers this option but it can be only used for onetext. We consider that it is more useful for the userto obtain statistics from various texts, in order toget significant statistical results. As the RSTtool,our tool allows to count the multinuclear relationsin two ways: a) one unit for each detectedmultinuclear relation, and b) one unit for eachdetected nucleus. If we use b), the statistics of themultinuclear relations of Table 2 are higher: List(864), Joint (537), Sequence (289), Contrast (153),Conjunction (28) and Disjunction (24).We are developing another tool, aimed toextract information from the annotated texts, whichwe will soon include into the interface. This toolwill allow to the user to select a subcorpus and toextract from it the EDUs corresponding to therhetorical relations selected, like a multidocumentspecialized summarizer guided by user's interests.The RST Spanish Treebank interface alsoincludes a screen which permits the users to sendtheir own annotated texts. Our aim is for the RSTSpanish Treebank to become a dynamic corpus, inconstant evolution, being increased with textsannotated by users. This has a double advantagesince, on the one hand, the corpus will grow and,on the other hand, users will profit from the7 http://www.corpus.unam.mx/rst/interface's applications, using their ownsubcorpora. The only requirement is to use therelations and the segmentation and annotationcriteria of our project. Once the texts are sent, theRST Spanish Treebank data manager will verify ifthe annotation corresponds to these criteria.</corps>
	<conclusion>
	We think that this work means an important stepfor the RST research in Spanish, and that the RSTSpanish Treebank will be useful to carry outdiverse researches about RST in this language,from a descriptive point of view (ex. analysis oftexts from different domains or genres) and anapplied point of view (development of discourseparsers and NLP applications, like automaticsummarization, automatic translation, IE, etc.).For the moment the corpus' size is acceptableand, though the percentage of double-annotatedtexts is not very high, we think that having 10annotators (using the same annotation manual)avoids the bias of only one annotator. In addition,the corpus includes texts of diverse domains andgenres, which provides us with a heterogeneousSpanish corpus. Moreover, the corpus interfacethat we have designed allows the user to select asubcorpus and to analyze it statistically. Inaddition, we think that it is essential to release afree corpus, on-line and dynamic, that is, incontinuous growth. Nevertheless, we are consciousthat our work still has certain limitations, which wewill try to solve in the future. In the short term, wehave 5 aims:a) To add one more annotator for the test corpusand to measure inter-annotator agreement.b) To use more agreement measures, like kappa.c) To reach a consensus on the annotation of thetest corpus, in order to establish a set of textsconsidered as a preliminary gold standard.d) To finish and to evaluate the IE tool.e) To analyze the corpus to extract linguisticpatterns for the automatic relations detection.In the long term, we consider other aims:f) To increase the corpus, by adding non-specialized texts, and new domains and genres.g) To annotate all the texts by 3 people, to get arepresentative gold-standard for Spanish (this aimwill depend on the funding of the project).8</conclusion>
	<discussion>
	</discussion>
	<biblio>
	Ron Artstein, and Massimo Poesio. 2008. SurveyArticle: Inter-Coder Agreement for ComputationalLinguistics. Computational Linguistics, 34(4):555-596.Nadjet Bouayad-Agha, Leo Wanner, and DanielNicklass. 2006. Discourse structuring of dynamiccontent. Procesamiento del lenguaje natural, 37:207-213.M. Teresa Cabre (1999). La terminologia:representacion y comunicacion. Barcelona: IULA-UPF.Lynn Carlson and Daniel Marcu. 2001. DiscourseTagging Reference Manual. ISI Technical ReportISITR-545. Los Angeles: University of SouthernCalifornia.Lynn Carlson, Daniel Marcu, and Mary EllenOkurowski. 2002a. RST Discourse Treebank.Pennsylvania: Linguistic Data Consortium.Lynn Carlson, Daniel Marcu, and Mary EllenOkurowski. 2002b. Building a Discourse-TaggedCorpus in the Framework of Rhetorical StructureTheory. In Proceedings of the 2nd SIGDIALWorkshop on Discourse and Dialogue, Eurospeech2001.Jacob Cohen. 1960. A coefficient of agreement fornominal scales. Educational and PsychologicalMeasurement, 20(1):37-46Iria da Cunha, Eric SanJuan, Juan-Manuel Torres-Moreno, Marina Lloberes, and Irene Castellon. 2010.Discourse Segmentation for Spanish based onShallow Parsing. Lecture Notes in ComputerScience, 6437:13-23.Iria da Cunha, and Mikel Iruskieta. 2010. Comparingrhetorical structures of different languages: Theinfluence of translation strategies. Discourse Studies,12(5):563-598.Iria da Cunha, Leo Wanner, and M. Teresa Cabre. 2007.Summarization of specialized discourse: The case ofmedical articles in Spanish. Terminology, 13(2):249-286.Dmitriy Dligach, Rodney D. Nielsen, and MarthaPalmer. 2010. To Annotate More Accurately or toAnnotate More. In Proceedings of the 4th LinguisticAnnotation Workshop (LAW-IV). 48th AnnualMeeting of the Association for ComputationalLinguistics.Joseph L. Fleis. 1971. Measuring nominal scaleagreement among many raters. PsychologicalBulletin, 76(5):378-382.Eduard Hovy. 2010. Annotation. A Tutorial. Presentedat the 48th Annual Meeting of the Association forComputational Linguistics.Nancy Ide and Pustejovsky, J. (2010). What DoesInteroperability Mean, anyway? Toward anOperational Definition of Interoperability. InProceedings of the Second International Conferenceon Global Interoperability for Language Resources(ICGL 2010).William C. Mann, and Sandra A. Thompson. 1988.Rhetorical structure theory: Toward a functionaltheory of text organization. Text, 8(3):243-281.Daniel Marcu. 2000. The Theory and Practice ofDiscourse Parsing Summarization. Massachusetts:Institute of Technology.Mitchell P. Marcus, Beatrice Santorini, Mary A.Marcinkiewicz. 1993. Building a large annotatedcorpus of English: the Penn Treenbank.Computational Linguistics, 19(2):313-330.Michael O'Donnell. 2000. RSTTOOL 2.4 - A markuptool for rhetorical structure theory. In Proceedings ofthe International Natural Language GenerationConference. 253-256.Martha Palmer, and Nianwen Xue. 2010. LinguisticAnnotation. Handbook of Computational Linguisticsand Natural Language Processing.Martha Palmer, Randee Tangi, Stephanie Strassel,Christiane Fellbaum, and Eduard Hovy (on-line).Historical Development and Future Directions inData Resource Development. MINDS report.http://www-nlpir.nist.gov/MINDS/FINAL/data.web.pdfSameer Pradhan, Eduard Hovy, Mitch Marcus, MarthaPalmer, Lance Ramshaw, Ralph Weischedel. 2007.OntoNotes: A Unified Relational SemanticRepresentation. In Proceedings of the First IEEEInternational Conference on Semantic Computing(ICSC-07).Rashmi Prasad, Nikhil Dinesh, Alan Lee, EleniMiltsakaki, Livio Robaldo, Aravind Joshi, andBonnie Webber. 2008. The Penn Discourse Treebank2.0. In Proceedings of the 6th InternationalConference on Language Resources and Evaluation(LREC 2008).David Reitter, and Mandred Stede. 2003. Step by step:underspecified markup in incremental rhetoricalanalysis. In Proceedings of the 4th International9Workshop on Linguistically Interpreted Corpora(LINC-03).Magdalena Romera. 2004. Discourse Functional Units:The Expression of Coherence Relations in SpokenSpanish. Munich: LINCOM.Thiago Alexandre Salgueiro Pardo, and Lucia HelenaMachado Rino. 2001. A summary planner based on athree-level discourse model. In Proceedings ofNatural Language Processing Pacific RimSymposium. 533-538.Thiago Alexandre Salgueiro Pardo, Maria das GracasVolpe Nunes, and Lucia Helena Machado Rino.2008. DiZer: An Automatic Discourse Analyzer forBrazilian Portuguese. Lecture Notes in ArtificialIntelligence, 3171:224-234.Thiago Alexandre Salgueiro Pardo, and Eloize RossiMarques Seno. 2005. Rhetalho: um corpus dereferencia anotado retoricamente. In Anais do VEncontro de Corpora. Sao Carlos-SP, Brasil.Gerardo Sierra. 2008. Diseno de corpus textuales parafines linguisticos. In Proceedings of the IX EncuentroInternacional de Linguistica en el Noroeste 2. 445-462.Manfred Stede. 2004. The Potsdam commentary corpus.In Proceedings of the Workshop on DiscourseAnnotation, 42nd Meeting of the Association forComputational Linguistics.Maite Taboada. 2004. Building Coherence andCohesion: Task-Oriented Dialogue in English andSpanish. Amsterdam/Philadelphia: John Benjamins.Maite Taboada, and Jan Renkema. 2008. DiscourseRelations Reference Corpus [Corpus]. Simon FraserUniversity and Tilburg University.http://www.sfu.ca/rst/06tools/discourse_relations_corpus.html.Maite Taboada, and William C. Mann. 2006a.Rhetorical Structure Theory: Looking Back andMoving Ahead. Discourse Studies, 8(3):423-459.Maite Taboada, and William C. Mann. 2006b.Applications of Rhetorical Structure Theory.Discourse Studies, 8(4):567-588.Milan Tofiloski, Julian Brooke, and Maite Taboada.2009. A Syntactic and Lexical-Based DiscourseSegmenter. In Proceedings of the 47th AnnualMeeting of the Association for ComputationalLinguistics.Hai Zhao, Yan Song, and Chunyu Kit. 2010. How Largea Corpus Do We Need: Statistical Method VersusRule-based Method. In Proceedings of the Seventhconference on International Language Resources andEvaluation (LREC'10).10
	</biblio>
</article>